/home/tf2387/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Using device: cuda
Setting up data...
Warning: Custom test directory not found. Creating dummy test loader.
Classes: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']
Creating medium model...
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 64, 32, 32]           1,728
       BatchNorm2d-2           [-1, 64, 32, 32]             128
            Conv2d-3           [-1, 64, 32, 32]          36,864
       BatchNorm2d-4           [-1, 64, 32, 32]             128
            Conv2d-5           [-1, 64, 32, 32]          36,864
       BatchNorm2d-6           [-1, 64, 32, 32]             128
        BasicBlock-7           [-1, 64, 32, 32]               0
            Conv2d-8           [-1, 64, 32, 32]          36,864
       BatchNorm2d-9           [-1, 64, 32, 32]             128
           Conv2d-10           [-1, 64, 32, 32]          36,864
      BatchNorm2d-11           [-1, 64, 32, 32]             128
       BasicBlock-12           [-1, 64, 32, 32]               0
           Conv2d-13           [-1, 64, 32, 32]          36,864
      BatchNorm2d-14           [-1, 64, 32, 32]             128
           Conv2d-15           [-1, 64, 32, 32]          36,864
      BatchNorm2d-16           [-1, 64, 32, 32]             128
       BasicBlock-17           [-1, 64, 32, 32]               0
           Conv2d-18          [-1, 128, 16, 16]          73,728
      BatchNorm2d-19          [-1, 128, 16, 16]             256
           Conv2d-20          [-1, 128, 16, 16]         147,456
      BatchNorm2d-21          [-1, 128, 16, 16]             256
           Conv2d-22          [-1, 128, 16, 16]           8,192
      BatchNorm2d-23          [-1, 128, 16, 16]             256
       BasicBlock-24          [-1, 128, 16, 16]               0
           Conv2d-25          [-1, 128, 16, 16]         147,456
      BatchNorm2d-26          [-1, 128, 16, 16]             256
           Conv2d-27          [-1, 128, 16, 16]         147,456
      BatchNorm2d-28          [-1, 128, 16, 16]             256
       BasicBlock-29          [-1, 128, 16, 16]               0
           Conv2d-30          [-1, 128, 16, 16]         147,456
      BatchNorm2d-31          [-1, 128, 16, 16]             256
           Conv2d-32          [-1, 128, 16, 16]         147,456
      BatchNorm2d-33          [-1, 128, 16, 16]             256
       BasicBlock-34          [-1, 128, 16, 16]               0
           Conv2d-35          [-1, 128, 16, 16]         147,456
      BatchNorm2d-36          [-1, 128, 16, 16]             256
           Conv2d-37          [-1, 128, 16, 16]         147,456
      BatchNorm2d-38          [-1, 128, 16, 16]             256
       BasicBlock-39          [-1, 128, 16, 16]               0
           Conv2d-40            [-1, 256, 8, 8]         294,912
      BatchNorm2d-41            [-1, 256, 8, 8]             512
           Conv2d-42            [-1, 256, 8, 8]         589,824
      BatchNorm2d-43            [-1, 256, 8, 8]             512
           Conv2d-44            [-1, 256, 8, 8]          32,768
      BatchNorm2d-45            [-1, 256, 8, 8]             512
       BasicBlock-46            [-1, 256, 8, 8]               0
           Conv2d-47            [-1, 256, 8, 8]         589,824
      BatchNorm2d-48            [-1, 256, 8, 8]             512
           Conv2d-49            [-1, 256, 8, 8]         589,824
      BatchNorm2d-50            [-1, 256, 8, 8]             512
       BasicBlock-51            [-1, 256, 8, 8]               0
           Conv2d-52            [-1, 256, 8, 8]         589,824
      BatchNorm2d-53            [-1, 256, 8, 8]             512
           Conv2d-54            [-1, 256, 8, 8]         589,824
      BatchNorm2d-55            [-1, 256, 8, 8]             512
       BasicBlock-56            [-1, 256, 8, 8]               0
AdaptiveAvgPool2d-57            [-1, 256, 1, 1]               0
           Linear-58                   [-1, 10]           2,570
================================================================
Total params: 4,623,178
Trainable params: 4,623,178
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 16.13
Params size (MB): 17.64
Estimated Total Size (MB): 33.77
----------------------------------------------------------------
None
Starting training for 200 epochs...

Epoch 1/200
Train Batch: 50/352 | Loss: 2.604 | Acc: 17.58% (1125/6400)
Train Batch: 100/352 | Loss: 2.270 | Acc: 20.95% (2682/12800)
Train Batch: 150/352 | Loss: 2.130 | Acc: 23.29% (4471/19200)
Train Batch: 200/352 | Loss: 2.044 | Acc: 25.17% (6444/25600)
Train Batch: 250/352 | Loss: 1.978 | Acc: 27.10% (8672/32000)
Train Batch: 300/352 | Loss: 1.929 | Acc: 28.68% (11015/38400)
Train Batch: 350/352 | Loss: 1.885 | Acc: 30.14% (13502/44800)
Train Batch: 352/352 | Loss: 1.884 | Acc: 30.15% (13569/45000)
Validation | Loss: 1.569 | Acc: 40.16% (2008/5000)
New best model with accuracy: 0.4016

Epoch 2/200
Train Batch: 50/352 | Loss: 1.559 | Acc: 41.20% (2637/6400)
Train Batch: 100/352 | Loss: 1.527 | Acc: 43.15% (5523/12800)
Train Batch: 150/352 | Loss: 1.498 | Acc: 44.55% (8553/19200)
Train Batch: 200/352 | Loss: 1.474 | Acc: 45.62% (11680/25600)
Train Batch: 250/352 | Loss: 1.448 | Acc: 46.73% (14954/32000)
Train Batch: 300/352 | Loss: 1.425 | Acc: 47.65% (18297/38400)
Train Batch: 350/352 | Loss: 1.398 | Acc: 48.72% (21828/44800)
Train Batch: 352/352 | Loss: 1.397 | Acc: 48.76% (21942/45000)
Validation | Loss: 1.137 | Acc: 58.68% (2934/5000)
New best model with accuracy: 0.5868

Epoch 3/200
Train Batch: 50/352 | Loss: 1.162 | Acc: 58.14% (3721/6400)
Train Batch: 100/352 | Loss: 1.126 | Acc: 59.74% (7647/12800)
Train Batch: 150/352 | Loss: 1.110 | Acc: 60.23% (11564/19200)
Train Batch: 200/352 | Loss: 1.092 | Acc: 60.81% (15567/25600)
Train Batch: 250/352 | Loss: 1.080 | Acc: 61.32% (19622/32000)
Train Batch: 300/352 | Loss: 1.065 | Acc: 61.90% (23769/38400)
Train Batch: 350/352 | Loss: 1.048 | Acc: 62.53% (28012/44800)
Train Batch: 352/352 | Loss: 1.048 | Acc: 62.52% (28133/45000)
Validation | Loss: 1.096 | Acc: 63.20% (3160/5000)
New best model with accuracy: 0.6320

Epoch 4/200
Train Batch: 50/352 | Loss: 0.884 | Acc: 68.84% (4406/6400)
Train Batch: 100/352 | Loss: 0.899 | Acc: 68.59% (8780/12800)
Train Batch: 150/352 | Loss: 0.884 | Acc: 69.02% (13252/19200)
Train Batch: 200/352 | Loss: 0.876 | Acc: 69.22% (17721/25600)
Train Batch: 250/352 | Loss: 0.869 | Acc: 69.48% (22234/32000)
Train Batch: 300/352 | Loss: 0.858 | Acc: 69.91% (26846/38400)
Train Batch: 350/352 | Loss: 0.846 | Acc: 70.46% (31566/44800)
Train Batch: 352/352 | Loss: 0.844 | Acc: 70.48% (31718/45000)
Validation | Loss: 1.557 | Acc: 56.94% (2847/5000)

Epoch 5/200
Train Batch: 50/352 | Loss: 0.743 | Acc: 74.23% (4751/6400)
Train Batch: 100/352 | Loss: 0.744 | Acc: 74.16% (9493/12800)
Train Batch: 150/352 | Loss: 0.735 | Acc: 74.48% (14301/19200)
Train Batch: 200/352 | Loss: 0.732 | Acc: 74.57% (19089/25600)
Train Batch: 250/352 | Loss: 0.728 | Acc: 74.74% (23918/32000)
Train Batch: 300/352 | Loss: 0.721 | Acc: 75.01% (28804/38400)
Train Batch: 350/352 | Loss: 0.716 | Acc: 75.17% (33674/44800)
Train Batch: 352/352 | Loss: 0.716 | Acc: 75.19% (33834/45000)
Validation | Loss: 0.861 | Acc: 71.34% (3567/5000)
New best model with accuracy: 0.7134

Epoch 6/200
Train Batch: 50/352 | Loss: 0.670 | Acc: 76.69% (4908/6400)
Train Batch: 100/352 | Loss: 0.652 | Acc: 77.37% (9903/12800)
Train Batch: 150/352 | Loss: 0.654 | Acc: 77.35% (14851/19200)
Train Batch: 200/352 | Loss: 0.650 | Acc: 77.65% (19879/25600)
Train Batch: 250/352 | Loss: 0.645 | Acc: 77.78% (24888/32000)
Train Batch: 300/352 | Loss: 0.645 | Acc: 77.83% (29887/38400)
Train Batch: 350/352 | Loss: 0.642 | Acc: 77.90% (34900/44800)
Train Batch: 352/352 | Loss: 0.641 | Acc: 77.92% (35065/45000)
Validation | Loss: 0.695 | Acc: 75.70% (3785/5000)
New best model with accuracy: 0.7570

Epoch 7/200
Train Batch: 50/352 | Loss: 0.605 | Acc: 79.69% (5100/6400)
Train Batch: 100/352 | Loss: 0.598 | Acc: 79.69% (10200/12800)
Train Batch: 150/352 | Loss: 0.604 | Acc: 79.38% (15241/19200)
Train Batch: 200/352 | Loss: 0.600 | Acc: 79.55% (20365/25600)
Train Batch: 250/352 | Loss: 0.600 | Acc: 79.40% (25408/32000)
Train Batch: 300/352 | Loss: 0.594 | Acc: 79.60% (30567/38400)
Train Batch: 350/352 | Loss: 0.594 | Acc: 79.70% (35704/44800)
Train Batch: 352/352 | Loss: 0.595 | Acc: 79.68% (35856/45000)
Validation | Loss: 0.777 | Acc: 73.52% (3676/5000)

Epoch 8/200
Train Batch: 50/352 | Loss: 0.541 | Acc: 81.25% (5200/6400)
Train Batch: 100/352 | Loss: 0.550 | Acc: 81.09% (10380/12800)
Train Batch: 150/352 | Loss: 0.553 | Acc: 81.14% (15579/19200)
Train Batch: 200/352 | Loss: 0.548 | Acc: 81.29% (20810/25600)
Train Batch: 250/352 | Loss: 0.551 | Acc: 81.17% (25973/32000)
Train Batch: 300/352 | Loss: 0.550 | Acc: 81.15% (31162/38400)
Train Batch: 350/352 | Loss: 0.553 | Acc: 81.07% (36319/44800)
Train Batch: 352/352 | Loss: 0.552 | Acc: 81.08% (36486/45000)
Validation | Loss: 0.601 | Acc: 79.00% (3950/5000)
New best model with accuracy: 0.7900

Epoch 9/200
Train Batch: 50/352 | Loss: 0.531 | Acc: 81.14% (5193/6400)
Train Batch: 100/352 | Loss: 0.532 | Acc: 81.73% (10461/12800)
Train Batch: 150/352 | Loss: 0.528 | Acc: 81.99% (15742/19200)
Train Batch: 200/352 | Loss: 0.528 | Acc: 81.99% (20989/25600)
Train Batch: 250/352 | Loss: 0.531 | Acc: 81.84% (26190/32000)
Train Batch: 300/352 | Loss: 0.529 | Acc: 81.90% (31450/38400)
Train Batch: 350/352 | Loss: 0.530 | Acc: 81.84% (36664/44800)
Train Batch: 352/352 | Loss: 0.530 | Acc: 81.86% (36835/45000)
Validation | Loss: 0.650 | Acc: 79.10% (3955/5000)
New best model with accuracy: 0.7910

Epoch 10/200
Train Batch: 50/352 | Loss: 0.473 | Acc: 83.66% (5354/6400)
Train Batch: 100/352 | Loss: 0.506 | Acc: 82.30% (10535/12800)
Train Batch: 150/352 | Loss: 0.510 | Acc: 82.26% (15793/19200)
Train Batch: 200/352 | Loss: 0.518 | Acc: 81.93% (20974/25600)
Train Batch: 250/352 | Loss: 0.512 | Acc: 82.24% (26316/32000)
Train Batch: 300/352 | Loss: 0.510 | Acc: 82.36% (31627/38400)
Train Batch: 350/352 | Loss: 0.510 | Acc: 82.29% (36866/44800)
Train Batch: 352/352 | Loss: 0.511 | Acc: 82.29% (37031/45000)
Validation | Loss: 0.636 | Acc: 77.26% (3863/5000)

Epoch 11/200
Train Batch: 50/352 | Loss: 0.483 | Acc: 83.14% (5321/6400)
Train Batch: 100/352 | Loss: 0.490 | Acc: 83.29% (10661/12800)
Train Batch: 150/352 | Loss: 0.480 | Acc: 83.54% (16039/19200)
Train Batch: 200/352 | Loss: 0.485 | Acc: 83.40% (21351/25600)
Train Batch: 250/352 | Loss: 0.484 | Acc: 83.48% (26713/32000)
Train Batch: 300/352 | Loss: 0.488 | Acc: 83.29% (31984/38400)
Train Batch: 350/352 | Loss: 0.483 | Acc: 83.48% (37398/44800)
Train Batch: 352/352 | Loss: 0.484 | Acc: 83.48% (37565/45000)
Validation | Loss: 0.555 | Acc: 81.10% (4055/5000)
New best model with accuracy: 0.8110

Epoch 12/200
Train Batch: 50/352 | Loss: 0.448 | Acc: 85.06% (5444/6400)
Train Batch: 100/352 | Loss: 0.457 | Acc: 84.53% (10820/12800)
Train Batch: 150/352 | Loss: 0.462 | Acc: 84.25% (16176/19200)
Train Batch: 200/352 | Loss: 0.461 | Acc: 84.40% (21607/25600)
Train Batch: 250/352 | Loss: 0.464 | Acc: 84.31% (26978/32000)
Train Batch: 300/352 | Loss: 0.467 | Acc: 84.17% (32323/38400)
Train Batch: 350/352 | Loss: 0.471 | Acc: 83.94% (37604/44800)
Train Batch: 352/352 | Loss: 0.470 | Acc: 83.96% (37780/45000)
Validation | Loss: 0.727 | Acc: 76.04% (3802/5000)

Epoch 13/200
Train Batch: 50/352 | Loss: 0.468 | Acc: 83.88% (5368/6400)
Train Batch: 100/352 | Loss: 0.454 | Acc: 84.48% (10813/12800)
Train Batch: 150/352 | Loss: 0.457 | Acc: 84.27% (16180/19200)
Train Batch: 200/352 | Loss: 0.456 | Acc: 84.21% (21558/25600)
Train Batch: 250/352 | Loss: 0.458 | Acc: 84.21% (26947/32000)
Train Batch: 300/352 | Loss: 0.458 | Acc: 84.22% (32339/38400)
Train Batch: 350/352 | Loss: 0.455 | Acc: 84.31% (37772/44800)
Train Batch: 352/352 | Loss: 0.455 | Acc: 84.30% (37933/45000)
Validation | Loss: 0.562 | Acc: 81.24% (4062/5000)
New best model with accuracy: 0.8124

Epoch 14/200
Train Batch: 50/352 | Loss: 0.448 | Acc: 84.88% (5432/6400)
Train Batch: 100/352 | Loss: 0.451 | Acc: 84.60% (10829/12800)
Train Batch: 150/352 | Loss: 0.448 | Acc: 84.77% (16275/19200)
Train Batch: 200/352 | Loss: 0.449 | Acc: 84.75% (21697/25600)
Train Batch: 250/352 | Loss: 0.450 | Acc: 84.72% (27109/32000)
Train Batch: 300/352 | Loss: 0.447 | Acc: 84.75% (32545/38400)
Train Batch: 350/352 | Loss: 0.448 | Acc: 84.75% (37967/44800)
Train Batch: 352/352 | Loss: 0.448 | Acc: 84.74% (38133/45000)
Validation | Loss: 0.700 | Acc: 76.48% (3824/5000)

Epoch 15/200
Train Batch: 50/352 | Loss: 0.417 | Acc: 85.52% (5473/6400)
Train Batch: 100/352 | Loss: 0.431 | Acc: 85.18% (10903/12800)
Train Batch: 150/352 | Loss: 0.437 | Acc: 84.96% (16313/19200)
Train Batch: 200/352 | Loss: 0.437 | Acc: 84.93% (21743/25600)
Train Batch: 250/352 | Loss: 0.438 | Acc: 84.98% (27193/32000)
Train Batch: 300/352 | Loss: 0.439 | Acc: 84.90% (32602/38400)
Train Batch: 350/352 | Loss: 0.437 | Acc: 85.01% (38083/44800)
Train Batch: 352/352 | Loss: 0.436 | Acc: 85.00% (38252/45000)
Validation | Loss: 0.526 | Acc: 81.90% (4095/5000)
New best model with accuracy: 0.8190

Epoch 16/200
Train Batch: 50/352 | Loss: 0.396 | Acc: 86.72% (5550/6400)
Train Batch: 100/352 | Loss: 0.412 | Acc: 86.09% (11019/12800)
Train Batch: 150/352 | Loss: 0.419 | Acc: 85.90% (16493/19200)
Train Batch: 200/352 | Loss: 0.423 | Acc: 85.64% (21923/25600)
Train Batch: 250/352 | Loss: 0.427 | Acc: 85.57% (27382/32000)
Train Batch: 300/352 | Loss: 0.428 | Acc: 85.52% (32840/38400)
Train Batch: 350/352 | Loss: 0.427 | Acc: 85.59% (38346/44800)
Train Batch: 352/352 | Loss: 0.427 | Acc: 85.59% (38515/45000)
Validation | Loss: 0.606 | Acc: 79.90% (3995/5000)

Epoch 17/200
Train Batch: 50/352 | Loss: 0.410 | Acc: 85.66% (5482/6400)
Train Batch: 100/352 | Loss: 0.410 | Acc: 85.52% (10947/12800)
Train Batch: 150/352 | Loss: 0.409 | Acc: 85.66% (16446/19200)
Train Batch: 200/352 | Loss: 0.411 | Acc: 85.77% (21956/25600)
Train Batch: 250/352 | Loss: 0.415 | Acc: 85.57% (27383/32000)
Train Batch: 300/352 | Loss: 0.417 | Acc: 85.54% (32848/38400)
Train Batch: 350/352 | Loss: 0.417 | Acc: 85.62% (38360/44800)
Train Batch: 352/352 | Loss: 0.416 | Acc: 85.64% (38537/45000)
Validation | Loss: 0.622 | Acc: 80.04% (4002/5000)

Epoch 18/200
Train Batch: 50/352 | Loss: 0.392 | Acc: 86.56% (5540/6400)
Train Batch: 100/352 | Loss: 0.398 | Acc: 86.59% (11083/12800)
Train Batch: 150/352 | Loss: 0.401 | Acc: 86.36% (16582/19200)
Train Batch: 200/352 | Loss: 0.406 | Acc: 86.10% (22042/25600)
Train Batch: 250/352 | Loss: 0.411 | Acc: 85.97% (27510/32000)
Train Batch: 300/352 | Loss: 0.413 | Acc: 85.88% (32977/38400)
Train Batch: 350/352 | Loss: 0.414 | Acc: 85.84% (38458/44800)
Train Batch: 352/352 | Loss: 0.414 | Acc: 85.84% (38626/45000)
Validation | Loss: 0.822 | Acc: 75.54% (3777/5000)

Epoch 19/200
Train Batch: 50/352 | Loss: 0.381 | Acc: 87.03% (5570/6400)
Train Batch: 100/352 | Loss: 0.382 | Acc: 86.95% (11130/12800)
Train Batch: 150/352 | Loss: 0.395 | Acc: 86.51% (16609/19200)
Train Batch: 200/352 | Loss: 0.402 | Acc: 86.34% (22102/25600)
Train Batch: 250/352 | Loss: 0.404 | Acc: 86.31% (27620/32000)
Train Batch: 300/352 | Loss: 0.401 | Acc: 86.37% (33165/38400)
Train Batch: 350/352 | Loss: 0.404 | Acc: 86.24% (38635/44800)
Train Batch: 352/352 | Loss: 0.404 | Acc: 86.21% (38795/45000)
Validation | Loss: 0.429 | Acc: 84.92% (4246/5000)
New best model with accuracy: 0.8492

Epoch 20/200
Train Batch: 50/352 | Loss: 0.389 | Acc: 86.56% (5540/6400)
Train Batch: 100/352 | Loss: 0.397 | Acc: 86.08% (11018/12800)
Train Batch: 150/352 | Loss: 0.390 | Acc: 86.34% (16578/19200)
Train Batch: 200/352 | Loss: 0.389 | Acc: 86.39% (22117/25600)
Train Batch: 250/352 | Loss: 0.389 | Acc: 86.47% (27671/32000)
Train Batch: 300/352 | Loss: 0.394 | Acc: 86.30% (33141/38400)
Train Batch: 350/352 | Loss: 0.396 | Acc: 86.28% (38653/44800)
Train Batch: 352/352 | Loss: 0.396 | Acc: 86.28% (38826/45000)
Validation | Loss: 0.550 | Acc: 81.84% (4092/5000)

Epoch 21/200
Train Batch: 50/352 | Loss: 0.386 | Acc: 86.56% (5540/6400)
Train Batch: 100/352 | Loss: 0.392 | Acc: 86.67% (11094/12800)
Train Batch: 150/352 | Loss: 0.388 | Acc: 86.66% (16639/19200)
Train Batch: 200/352 | Loss: 0.390 | Acc: 86.55% (22158/25600)
Train Batch: 250/352 | Loss: 0.389 | Acc: 86.68% (27739/32000)
Train Batch: 300/352 | Loss: 0.388 | Acc: 86.79% (33326/38400)
Train Batch: 350/352 | Loss: 0.389 | Acc: 86.73% (38853/44800)
Train Batch: 352/352 | Loss: 0.389 | Acc: 86.73% (39027/45000)
Validation | Loss: 0.577 | Acc: 80.66% (4033/5000)

Epoch 22/200
Train Batch: 50/352 | Loss: 0.374 | Acc: 87.34% (5590/6400)
Train Batch: 100/352 | Loss: 0.369 | Acc: 87.53% (11204/12800)
Train Batch: 150/352 | Loss: 0.376 | Acc: 87.18% (16738/19200)
Train Batch: 200/352 | Loss: 0.375 | Acc: 87.18% (22317/25600)
Train Batch: 250/352 | Loss: 0.379 | Acc: 87.04% (27854/32000)
Train Batch: 300/352 | Loss: 0.383 | Acc: 86.94% (33384/38400)
Train Batch: 350/352 | Loss: 0.385 | Acc: 86.88% (38920/44800)
Train Batch: 352/352 | Loss: 0.384 | Acc: 86.87% (39093/45000)
Validation | Loss: 0.618 | Acc: 79.28% (3964/5000)

Epoch 23/200
Train Batch: 50/352 | Loss: 0.355 | Acc: 87.70% (5613/6400)
Train Batch: 100/352 | Loss: 0.371 | Acc: 87.20% (11161/12800)
Train Batch: 150/352 | Loss: 0.374 | Acc: 86.96% (16697/19200)
Train Batch: 200/352 | Loss: 0.379 | Acc: 86.96% (22262/25600)
Train Batch: 250/352 | Loss: 0.384 | Acc: 86.78% (27770/32000)
Train Batch: 300/352 | Loss: 0.386 | Acc: 86.68% (33284/38400)
Train Batch: 350/352 | Loss: 0.388 | Acc: 86.62% (38804/44800)
Train Batch: 352/352 | Loss: 0.388 | Acc: 86.62% (38978/45000)
Validation | Loss: 0.501 | Acc: 83.32% (4166/5000)

Epoch 24/200
Train Batch: 50/352 | Loss: 0.363 | Acc: 87.53% (5602/6400)
Train Batch: 100/352 | Loss: 0.377 | Acc: 87.13% (11153/12800)
Train Batch: 150/352 | Loss: 0.369 | Acc: 87.37% (16775/19200)
Train Batch: 200/352 | Loss: 0.369 | Acc: 87.42% (22379/25600)
Train Batch: 250/352 | Loss: 0.371 | Acc: 87.36% (27954/32000)
Train Batch: 300/352 | Loss: 0.371 | Acc: 87.34% (33540/38400)
Train Batch: 350/352 | Loss: 0.374 | Acc: 87.30% (39109/44800)
Train Batch: 352/352 | Loss: 0.374 | Acc: 87.29% (39281/45000)
Validation | Loss: 0.599 | Acc: 80.98% (4049/5000)

Epoch 25/200
Train Batch: 50/352 | Loss: 0.343 | Acc: 87.94% (5628/6400)
Train Batch: 100/352 | Loss: 0.346 | Acc: 88.02% (11266/12800)
Train Batch: 150/352 | Loss: 0.348 | Acc: 87.70% (16838/19200)
Train Batch: 200/352 | Loss: 0.355 | Acc: 87.54% (22410/25600)
Train Batch: 250/352 | Loss: 0.363 | Acc: 87.41% (27972/32000)
Train Batch: 300/352 | Loss: 0.368 | Acc: 87.25% (33503/38400)
Train Batch: 350/352 | Loss: 0.369 | Acc: 87.25% (39086/44800)
Train Batch: 352/352 | Loss: 0.369 | Acc: 87.24% (39257/45000)
Validation | Loss: 0.489 | Acc: 84.28% (4214/5000)

Epoch 26/200
Train Batch: 50/352 | Loss: 0.323 | Acc: 88.88% (5688/6400)
Train Batch: 100/352 | Loss: 0.337 | Acc: 88.61% (11342/12800)
Train Batch: 150/352 | Loss: 0.345 | Acc: 88.29% (16952/19200)
Train Batch: 200/352 | Loss: 0.349 | Acc: 88.09% (22550/25600)
Train Batch: 250/352 | Loss: 0.354 | Acc: 87.92% (28135/32000)
Train Batch: 300/352 | Loss: 0.356 | Acc: 87.82% (33722/38400)
Train Batch: 350/352 | Loss: 0.361 | Acc: 87.64% (39264/44800)
Train Batch: 352/352 | Loss: 0.361 | Acc: 87.63% (39433/45000)
Validation | Loss: 0.697 | Acc: 79.18% (3959/5000)

Epoch 27/200
Train Batch: 50/352 | Loss: 0.363 | Acc: 87.19% (5580/6400)
Train Batch: 100/352 | Loss: 0.363 | Acc: 87.47% (11196/12800)
Train Batch: 150/352 | Loss: 0.356 | Acc: 87.80% (16858/19200)
Train Batch: 200/352 | Loss: 0.355 | Acc: 87.91% (22504/25600)
Train Batch: 250/352 | Loss: 0.360 | Acc: 87.78% (28088/32000)
Train Batch: 300/352 | Loss: 0.361 | Acc: 87.72% (33686/38400)
Train Batch: 350/352 | Loss: 0.365 | Acc: 87.55% (39223/44800)
Train Batch: 352/352 | Loss: 0.365 | Acc: 87.55% (39396/45000)
Validation | Loss: 0.823 | Acc: 77.36% (3868/5000)

Epoch 28/200
Train Batch: 50/352 | Loss: 0.337 | Acc: 88.42% (5659/6400)
Train Batch: 100/352 | Loss: 0.348 | Acc: 87.91% (11252/12800)
Train Batch: 150/352 | Loss: 0.351 | Acc: 88.06% (16908/19200)
Train Batch: 200/352 | Loss: 0.354 | Acc: 87.98% (22523/25600)
Train Batch: 250/352 | Loss: 0.358 | Acc: 87.84% (28108/32000)
Train Batch: 300/352 | Loss: 0.356 | Acc: 87.94% (33768/38400)
Train Batch: 350/352 | Loss: 0.361 | Acc: 87.82% (39342/44800)
Train Batch: 352/352 | Loss: 0.361 | Acc: 87.80% (39511/45000)
Validation | Loss: 0.464 | Acc: 84.38% (4219/5000)

Epoch 29/200
Train Batch: 50/352 | Loss: 0.320 | Acc: 89.22% (5710/6400)
Train Batch: 100/352 | Loss: 0.340 | Acc: 88.25% (11296/12800)
Train Batch: 150/352 | Loss: 0.347 | Acc: 87.98% (16892/19200)
Train Batch: 200/352 | Loss: 0.351 | Acc: 87.85% (22489/25600)
Train Batch: 250/352 | Loss: 0.348 | Acc: 88.03% (28168/32000)
Train Batch: 300/352 | Loss: 0.355 | Acc: 87.79% (33712/38400)
Train Batch: 350/352 | Loss: 0.356 | Acc: 87.77% (39323/44800)
Train Batch: 352/352 | Loss: 0.356 | Acc: 87.76% (39490/45000)
Validation | Loss: 0.669 | Acc: 79.96% (3998/5000)

Epoch 30/200
Train Batch: 50/352 | Loss: 0.329 | Acc: 88.62% (5672/6400)
Train Batch: 100/352 | Loss: 0.339 | Acc: 88.38% (11313/12800)
Train Batch: 150/352 | Loss: 0.342 | Acc: 88.35% (16964/19200)
Train Batch: 200/352 | Loss: 0.349 | Acc: 88.05% (22541/25600)
Train Batch: 250/352 | Loss: 0.349 | Acc: 87.95% (28145/32000)
Train Batch: 300/352 | Loss: 0.349 | Acc: 87.99% (33789/38400)
Train Batch: 350/352 | Loss: 0.351 | Acc: 87.95% (39403/44800)
Train Batch: 352/352 | Loss: 0.351 | Acc: 87.96% (39581/45000)
Validation | Loss: 0.416 | Acc: 85.56% (4278/5000)
New best model with accuracy: 0.8556

Epoch 31/200
Train Batch: 50/352 | Loss: 0.346 | Acc: 88.09% (5638/6400)
Train Batch: 100/352 | Loss: 0.350 | Acc: 88.03% (11268/12800)
Train Batch: 150/352 | Loss: 0.348 | Acc: 88.05% (16905/19200)
Train Batch: 200/352 | Loss: 0.350 | Acc: 88.03% (22535/25600)
Train Batch: 250/352 | Loss: 0.348 | Acc: 88.07% (28181/32000)
Train Batch: 300/352 | Loss: 0.351 | Acc: 87.90% (33753/38400)
Train Batch: 350/352 | Loss: 0.349 | Acc: 88.01% (39427/44800)
Train Batch: 352/352 | Loss: 0.350 | Acc: 88.01% (39603/45000)
Validation | Loss: 0.497 | Acc: 83.38% (4169/5000)

Epoch 32/200
Train Batch: 50/352 | Loss: 0.321 | Acc: 89.06% (5700/6400)
Train Batch: 100/352 | Loss: 0.325 | Acc: 88.70% (11353/12800)
Train Batch: 150/352 | Loss: 0.323 | Acc: 88.90% (17069/19200)
Train Batch: 200/352 | Loss: 0.329 | Acc: 88.67% (22699/25600)
Train Batch: 250/352 | Loss: 0.333 | Acc: 88.51% (28323/32000)
Train Batch: 300/352 | Loss: 0.335 | Acc: 88.51% (33986/38400)
Train Batch: 350/352 | Loss: 0.339 | Acc: 88.43% (39615/44800)
Train Batch: 352/352 | Loss: 0.339 | Acc: 88.43% (39793/45000)
Validation | Loss: 0.592 | Acc: 80.82% (4041/5000)

Epoch 33/200
Train Batch: 50/352 | Loss: 0.323 | Acc: 88.67% (5675/6400)
Train Batch: 100/352 | Loss: 0.326 | Acc: 88.73% (11358/12800)
Train Batch: 150/352 | Loss: 0.325 | Acc: 88.85% (17059/19200)
Train Batch: 200/352 | Loss: 0.337 | Acc: 88.47% (22649/25600)
Train Batch: 250/352 | Loss: 0.342 | Acc: 88.39% (28286/32000)
Train Batch: 300/352 | Loss: 0.345 | Acc: 88.36% (33931/38400)
Train Batch: 350/352 | Loss: 0.347 | Acc: 88.26% (39540/44800)
Train Batch: 352/352 | Loss: 0.348 | Acc: 88.26% (39715/45000)
Validation | Loss: 0.450 | Acc: 84.62% (4231/5000)

Epoch 34/200
Train Batch: 50/352 | Loss: 0.316 | Acc: 89.02% (5697/6400)
Train Batch: 100/352 | Loss: 0.325 | Acc: 88.89% (11378/12800)
Train Batch: 150/352 | Loss: 0.337 | Acc: 88.55% (17002/19200)
Train Batch: 200/352 | Loss: 0.339 | Acc: 88.53% (22663/25600)
Train Batch: 250/352 | Loss: 0.338 | Acc: 88.55% (28335/32000)
Train Batch: 300/352 | Loss: 0.342 | Acc: 88.34% (33922/38400)
Train Batch: 350/352 | Loss: 0.342 | Acc: 88.32% (39567/44800)
Train Batch: 352/352 | Loss: 0.342 | Acc: 88.30% (39733/45000)
Validation | Loss: 0.476 | Acc: 83.86% (4193/5000)

Epoch 35/200
Train Batch: 50/352 | Loss: 0.321 | Acc: 89.11% (5703/6400)
Train Batch: 100/352 | Loss: 0.318 | Acc: 89.05% (11399/12800)
Train Batch: 150/352 | Loss: 0.329 | Acc: 88.65% (17020/19200)
Train Batch: 200/352 | Loss: 0.338 | Acc: 88.43% (22637/25600)
Train Batch: 250/352 | Loss: 0.341 | Acc: 88.33% (28266/32000)
Train Batch: 300/352 | Loss: 0.344 | Acc: 88.17% (33856/38400)
Train Batch: 350/352 | Loss: 0.347 | Acc: 88.11% (39475/44800)
Train Batch: 352/352 | Loss: 0.347 | Acc: 88.11% (39649/45000)
Validation | Loss: 0.668 | Acc: 78.46% (3923/5000)

Epoch 36/200
Train Batch: 50/352 | Loss: 0.318 | Acc: 89.30% (5715/6400)
Train Batch: 100/352 | Loss: 0.316 | Acc: 89.33% (11434/12800)
Train Batch: 150/352 | Loss: 0.320 | Acc: 89.11% (17109/19200)
Train Batch: 200/352 | Loss: 0.327 | Acc: 88.92% (22764/25600)
Train Batch: 250/352 | Loss: 0.328 | Acc: 88.88% (28443/32000)
Train Batch: 300/352 | Loss: 0.327 | Acc: 88.97% (34164/38400)
Train Batch: 350/352 | Loss: 0.329 | Acc: 88.85% (39807/44800)
Train Batch: 352/352 | Loss: 0.329 | Acc: 88.85% (39982/45000)
Validation | Loss: 0.457 | Acc: 84.40% (4220/5000)

Epoch 37/200
Train Batch: 50/352 | Loss: 0.296 | Acc: 89.88% (5752/6400)
Train Batch: 100/352 | Loss: 0.319 | Acc: 89.09% (11404/12800)
Train Batch: 150/352 | Loss: 0.325 | Acc: 88.87% (17063/19200)
Train Batch: 200/352 | Loss: 0.330 | Acc: 88.79% (22730/25600)
Train Batch: 250/352 | Loss: 0.337 | Acc: 88.70% (28383/32000)
Train Batch: 300/352 | Loss: 0.338 | Acc: 88.64% (34039/38400)
Train Batch: 350/352 | Loss: 0.337 | Acc: 88.71% (39744/44800)
Train Batch: 352/352 | Loss: 0.337 | Acc: 88.71% (39919/45000)
Validation | Loss: 0.526 | Acc: 83.18% (4159/5000)

Epoch 38/200
Train Batch: 50/352 | Loss: 0.318 | Acc: 89.19% (5708/6400)
Train Batch: 100/352 | Loss: 0.311 | Acc: 89.40% (11443/12800)
Train Batch: 150/352 | Loss: 0.313 | Acc: 89.24% (17134/19200)
Train Batch: 200/352 | Loss: 0.320 | Acc: 88.98% (22779/25600)
Train Batch: 250/352 | Loss: 0.323 | Acc: 88.80% (28416/32000)
Train Batch: 300/352 | Loss: 0.328 | Acc: 88.70% (34062/38400)
Train Batch: 350/352 | Loss: 0.332 | Acc: 88.60% (39692/44800)
Train Batch: 352/352 | Loss: 0.333 | Acc: 88.61% (39874/45000)
Validation | Loss: 0.687 | Acc: 79.20% (3960/5000)

Epoch 39/200
Train Batch: 50/352 | Loss: 0.309 | Acc: 89.34% (5718/6400)
Train Batch: 100/352 | Loss: 0.316 | Acc: 89.04% (11397/12800)
Train Batch: 150/352 | Loss: 0.315 | Acc: 89.18% (17122/19200)
Train Batch: 200/352 | Loss: 0.323 | Acc: 88.91% (22761/25600)
Train Batch: 250/352 | Loss: 0.324 | Acc: 88.88% (28441/32000)
Train Batch: 300/352 | Loss: 0.325 | Acc: 88.81% (34103/38400)
Train Batch: 350/352 | Loss: 0.324 | Acc: 88.82% (39793/44800)
Train Batch: 352/352 | Loss: 0.325 | Acc: 88.82% (39971/45000)
Validation | Loss: 0.506 | Acc: 83.36% (4168/5000)

Epoch 40/200
Train Batch: 50/352 | Loss: 0.325 | Acc: 88.47% (5662/6400)
Train Batch: 100/352 | Loss: 0.316 | Acc: 89.16% (11412/12800)
Train Batch: 150/352 | Loss: 0.323 | Acc: 88.86% (17061/19200)
Train Batch: 200/352 | Loss: 0.327 | Acc: 88.71% (22709/25600)
Train Batch: 250/352 | Loss: 0.328 | Acc: 88.74% (28397/32000)
Train Batch: 300/352 | Loss: 0.327 | Acc: 88.79% (34097/38400)
Train Batch: 350/352 | Loss: 0.328 | Acc: 88.81% (39786/44800)
Train Batch: 352/352 | Loss: 0.328 | Acc: 88.79% (39956/45000)
Validation | Loss: 0.408 | Acc: 86.28% (4314/5000)
New best model with accuracy: 0.8628

Epoch 41/200
Train Batch: 50/352 | Loss: 0.310 | Acc: 89.12% (5704/6400)
Train Batch: 100/352 | Loss: 0.312 | Acc: 89.04% (11397/12800)
Train Batch: 150/352 | Loss: 0.309 | Acc: 89.10% (17108/19200)
Train Batch: 200/352 | Loss: 0.310 | Acc: 89.17% (22828/25600)
Train Batch: 250/352 | Loss: 0.312 | Acc: 89.16% (28532/32000)
Train Batch: 300/352 | Loss: 0.316 | Acc: 89.07% (34201/38400)
Train Batch: 350/352 | Loss: 0.321 | Acc: 88.91% (39830/44800)
Train Batch: 352/352 | Loss: 0.321 | Acc: 88.90% (40007/45000)
Validation | Loss: 0.479 | Acc: 83.60% (4180/5000)

Epoch 42/200
Train Batch: 50/352 | Loss: 0.320 | Acc: 89.39% (5721/6400)
Train Batch: 100/352 | Loss: 0.307 | Acc: 89.58% (11466/12800)
Train Batch: 150/352 | Loss: 0.313 | Acc: 89.42% (17169/19200)
Train Batch: 200/352 | Loss: 0.315 | Acc: 89.38% (22881/25600)
Train Batch: 250/352 | Loss: 0.314 | Acc: 89.42% (28615/32000)
Train Batch: 300/352 | Loss: 0.318 | Acc: 89.33% (34303/38400)
Train Batch: 350/352 | Loss: 0.319 | Acc: 89.26% (39990/44800)
Train Batch: 352/352 | Loss: 0.319 | Acc: 89.26% (40168/45000)
Validation | Loss: 0.451 | Acc: 84.26% (4213/5000)

Epoch 43/200
Train Batch: 50/352 | Loss: 0.300 | Acc: 89.67% (5739/6400)
Train Batch: 100/352 | Loss: 0.295 | Acc: 89.97% (11516/12800)
Train Batch: 150/352 | Loss: 0.301 | Acc: 89.80% (17242/19200)
Train Batch: 200/352 | Loss: 0.308 | Acc: 89.54% (22922/25600)
Train Batch: 250/352 | Loss: 0.311 | Acc: 89.44% (28620/32000)
Train Batch: 300/352 | Loss: 0.314 | Acc: 89.40% (34328/38400)
Train Batch: 350/352 | Loss: 0.316 | Acc: 89.33% (40019/44800)
Train Batch: 352/352 | Loss: 0.317 | Acc: 89.32% (40193/45000)
Validation | Loss: 0.890 | Acc: 74.58% (3729/5000)

Epoch 44/200
Train Batch: 50/352 | Loss: 0.308 | Acc: 89.58% (5733/6400)
Train Batch: 100/352 | Loss: 0.299 | Acc: 89.75% (11488/12800)
Train Batch: 150/352 | Loss: 0.299 | Acc: 89.77% (17235/19200)
Train Batch: 200/352 | Loss: 0.313 | Acc: 89.36% (22875/25600)
Train Batch: 250/352 | Loss: 0.314 | Acc: 89.37% (28599/32000)
Train Batch: 300/352 | Loss: 0.322 | Acc: 89.16% (34238/38400)
Train Batch: 350/352 | Loss: 0.321 | Acc: 89.18% (39951/44800)
Train Batch: 352/352 | Loss: 0.321 | Acc: 89.18% (40129/45000)
Validation | Loss: 0.535 | Acc: 82.48% (4124/5000)

Epoch 45/200
Train Batch: 50/352 | Loss: 0.284 | Acc: 90.17% (5771/6400)
Train Batch: 100/352 | Loss: 0.303 | Acc: 89.56% (11464/12800)
Train Batch: 150/352 | Loss: 0.302 | Acc: 89.51% (17186/19200)
Train Batch: 200/352 | Loss: 0.305 | Acc: 89.44% (22897/25600)
Train Batch: 250/352 | Loss: 0.312 | Acc: 89.17% (28533/32000)
Train Batch: 300/352 | Loss: 0.313 | Acc: 89.16% (34238/38400)
Train Batch: 350/352 | Loss: 0.317 | Acc: 89.05% (39896/44800)
Train Batch: 352/352 | Loss: 0.317 | Acc: 89.03% (40065/45000)
Validation | Loss: 0.475 | Acc: 83.42% (4171/5000)

Epoch 46/200
Train Batch: 50/352 | Loss: 0.320 | Acc: 88.84% (5686/6400)
Train Batch: 100/352 | Loss: 0.315 | Acc: 89.14% (11410/12800)
Train Batch: 150/352 | Loss: 0.310 | Acc: 89.33% (17152/19200)
Train Batch: 200/352 | Loss: 0.308 | Acc: 89.41% (22889/25600)
Train Batch: 250/352 | Loss: 0.310 | Acc: 89.36% (28594/32000)
Train Batch: 300/352 | Loss: 0.313 | Acc: 89.30% (34292/38400)
Train Batch: 350/352 | Loss: 0.313 | Acc: 89.31% (40011/44800)
Train Batch: 352/352 | Loss: 0.314 | Acc: 89.29% (40182/45000)
Validation | Loss: 0.602 | Acc: 79.54% (3977/5000)

Epoch 47/200
Train Batch: 50/352 | Loss: 0.295 | Acc: 89.92% (5755/6400)
Train Batch: 100/352 | Loss: 0.301 | Acc: 89.62% (11471/12800)
Train Batch: 150/352 | Loss: 0.304 | Acc: 89.66% (17215/19200)
Train Batch: 200/352 | Loss: 0.305 | Acc: 89.66% (22952/25600)
Train Batch: 250/352 | Loss: 0.311 | Acc: 89.47% (28629/32000)
Train Batch: 300/352 | Loss: 0.308 | Acc: 89.58% (34400/38400)
Train Batch: 350/352 | Loss: 0.311 | Acc: 89.44% (40069/44800)
Train Batch: 352/352 | Loss: 0.311 | Acc: 89.44% (40249/45000)
Validation | Loss: 0.450 | Acc: 85.24% (4262/5000)

Epoch 48/200
Train Batch: 50/352 | Loss: 0.271 | Acc: 90.59% (5798/6400)
Train Batch: 100/352 | Loss: 0.295 | Acc: 89.88% (11504/12800)
Train Batch: 150/352 | Loss: 0.294 | Acc: 89.89% (17258/19200)
Train Batch: 200/352 | Loss: 0.297 | Acc: 89.74% (22974/25600)
Train Batch: 250/352 | Loss: 0.303 | Acc: 89.56% (28658/32000)
Train Batch: 300/352 | Loss: 0.304 | Acc: 89.50% (34368/38400)
Train Batch: 350/352 | Loss: 0.305 | Acc: 89.49% (40092/44800)
Train Batch: 352/352 | Loss: 0.305 | Acc: 89.50% (40273/45000)
Validation | Loss: 0.468 | Acc: 83.94% (4197/5000)

Epoch 49/200
Train Batch: 50/352 | Loss: 0.292 | Acc: 90.25% (5776/6400)
Train Batch: 100/352 | Loss: 0.301 | Acc: 89.87% (11503/12800)
Train Batch: 150/352 | Loss: 0.293 | Acc: 90.16% (17311/19200)
Train Batch: 200/352 | Loss: 0.294 | Acc: 90.02% (23044/25600)
Train Batch: 250/352 | Loss: 0.298 | Acc: 89.87% (28758/32000)
Train Batch: 300/352 | Loss: 0.303 | Acc: 89.72% (34453/38400)
Train Batch: 350/352 | Loss: 0.303 | Acc: 89.72% (40195/44800)
Train Batch: 352/352 | Loss: 0.303 | Acc: 89.71% (40368/45000)
Validation | Loss: 0.483 | Acc: 83.86% (4193/5000)

Epoch 50/200
Train Batch: 50/352 | Loss: 0.289 | Acc: 90.03% (5762/6400)
Train Batch: 100/352 | Loss: 0.296 | Acc: 89.56% (11464/12800)
Train Batch: 150/352 | Loss: 0.301 | Acc: 89.49% (17182/19200)
Train Batch: 200/352 | Loss: 0.300 | Acc: 89.58% (22933/25600)
Train Batch: 250/352 | Loss: 0.299 | Acc: 89.60% (28672/32000)
Train Batch: 300/352 | Loss: 0.299 | Acc: 89.65% (34425/38400)
Train Batch: 350/352 | Loss: 0.305 | Acc: 89.50% (40095/44800)
Train Batch: 352/352 | Loss: 0.305 | Acc: 89.50% (40276/45000)
Validation | Loss: 0.495 | Acc: 84.06% (4203/5000)

Epoch 51/200
Train Batch: 50/352 | Loss: 0.273 | Acc: 90.22% (5774/6400)
Train Batch: 100/352 | Loss: 0.278 | Acc: 90.38% (11569/12800)
Train Batch: 150/352 | Loss: 0.288 | Acc: 90.13% (17305/19200)
Train Batch: 200/352 | Loss: 0.294 | Acc: 89.97% (23032/25600)
Train Batch: 250/352 | Loss: 0.295 | Acc: 89.94% (28781/32000)
Train Batch: 300/352 | Loss: 0.296 | Acc: 89.92% (34528/38400)
Train Batch: 350/352 | Loss: 0.300 | Acc: 89.79% (40226/44800)
Train Batch: 352/352 | Loss: 0.300 | Acc: 89.79% (40406/45000)
Validation | Loss: 0.417 | Acc: 85.38% (4269/5000)

Epoch 52/200
Train Batch: 50/352 | Loss: 0.287 | Acc: 90.47% (5790/6400)
Train Batch: 100/352 | Loss: 0.283 | Acc: 90.38% (11568/12800)
Train Batch: 150/352 | Loss: 0.296 | Acc: 89.78% (17238/19200)
Train Batch: 200/352 | Loss: 0.298 | Acc: 89.76% (22979/25600)
Train Batch: 250/352 | Loss: 0.297 | Acc: 89.73% (28713/32000)
Train Batch: 300/352 | Loss: 0.298 | Acc: 89.76% (34466/38400)
Train Batch: 350/352 | Loss: 0.301 | Acc: 89.70% (40184/44800)
Train Batch: 352/352 | Loss: 0.301 | Acc: 89.70% (40367/45000)
Validation | Loss: 0.392 | Acc: 86.40% (4320/5000)
New best model with accuracy: 0.8640

Epoch 53/200
Train Batch: 50/352 | Loss: 0.299 | Acc: 89.83% (5749/6400)
Train Batch: 100/352 | Loss: 0.296 | Acc: 89.77% (11491/12800)
Train Batch: 150/352 | Loss: 0.303 | Acc: 89.56% (17196/19200)
Train Batch: 200/352 | Loss: 0.304 | Acc: 89.56% (22927/25600)
Train Batch: 250/352 | Loss: 0.305 | Acc: 89.64% (28684/32000)
Train Batch: 300/352 | Loss: 0.307 | Acc: 89.56% (34390/38400)
Train Batch: 350/352 | Loss: 0.306 | Acc: 89.58% (40130/44800)
Train Batch: 352/352 | Loss: 0.306 | Acc: 89.58% (40310/45000)
Validation | Loss: 0.575 | Acc: 82.10% (4105/5000)

Epoch 54/200
Train Batch: 50/352 | Loss: 0.289 | Acc: 90.36% (5783/6400)
Train Batch: 100/352 | Loss: 0.279 | Acc: 90.50% (11584/12800)
Train Batch: 150/352 | Loss: 0.277 | Acc: 90.35% (17348/19200)
Train Batch: 200/352 | Loss: 0.282 | Acc: 90.26% (23107/25600)
Train Batch: 250/352 | Loss: 0.288 | Acc: 90.12% (28839/32000)
Train Batch: 300/352 | Loss: 0.293 | Acc: 89.94% (34536/38400)
Train Batch: 350/352 | Loss: 0.296 | Acc: 89.84% (40248/44800)
Train Batch: 352/352 | Loss: 0.296 | Acc: 89.86% (40439/45000)
Validation | Loss: 0.550 | Acc: 81.78% (4089/5000)

Epoch 55/200
Train Batch: 50/352 | Loss: 0.270 | Acc: 90.66% (5802/6400)
Train Batch: 100/352 | Loss: 0.283 | Acc: 90.20% (11545/12800)
Train Batch: 150/352 | Loss: 0.286 | Acc: 90.13% (17305/19200)
Train Batch: 200/352 | Loss: 0.295 | Acc: 89.79% (22985/25600)
Train Batch: 250/352 | Loss: 0.296 | Acc: 89.80% (28735/32000)
Train Batch: 300/352 | Loss: 0.299 | Acc: 89.73% (34456/38400)
Train Batch: 350/352 | Loss: 0.296 | Acc: 89.85% (40255/44800)
Train Batch: 352/352 | Loss: 0.296 | Acc: 89.84% (40430/45000)
Validation | Loss: 0.373 | Acc: 87.02% (4351/5000)
New best model with accuracy: 0.8702

Epoch 56/200
Train Batch: 50/352 | Loss: 0.290 | Acc: 90.03% (5762/6400)
Train Batch: 100/352 | Loss: 0.282 | Acc: 90.40% (11571/12800)
Train Batch: 150/352 | Loss: 0.284 | Acc: 90.32% (17341/19200)
Train Batch: 200/352 | Loss: 0.285 | Acc: 90.26% (23107/25600)
Train Batch: 250/352 | Loss: 0.290 | Acc: 90.09% (28828/32000)
Train Batch: 300/352 | Loss: 0.289 | Acc: 90.14% (34615/38400)
Train Batch: 350/352 | Loss: 0.291 | Acc: 90.09% (40362/44800)
Train Batch: 352/352 | Loss: 0.291 | Acc: 90.09% (40540/45000)
Validation | Loss: 0.606 | Acc: 81.22% (4061/5000)

Epoch 57/200
Train Batch: 50/352 | Loss: 0.279 | Acc: 90.22% (5774/6400)
Train Batch: 100/352 | Loss: 0.289 | Acc: 90.05% (11526/12800)
Train Batch: 150/352 | Loss: 0.293 | Acc: 90.01% (17281/19200)
Train Batch: 200/352 | Loss: 0.292 | Acc: 90.04% (23051/25600)
Train Batch: 250/352 | Loss: 0.292 | Acc: 90.05% (28817/32000)
Train Batch: 300/352 | Loss: 0.292 | Acc: 89.99% (34556/38400)
Train Batch: 350/352 | Loss: 0.295 | Acc: 89.91% (40279/44800)
Train Batch: 352/352 | Loss: 0.295 | Acc: 89.89% (40452/45000)
Validation | Loss: 0.468 | Acc: 84.68% (4234/5000)

Epoch 58/200
Train Batch: 50/352 | Loss: 0.274 | Acc: 90.88% (5816/6400)
Train Batch: 100/352 | Loss: 0.281 | Acc: 90.69% (11608/12800)
Train Batch: 150/352 | Loss: 0.287 | Acc: 90.47% (17370/19200)
Train Batch: 200/352 | Loss: 0.286 | Acc: 90.43% (23151/25600)
Train Batch: 250/352 | Loss: 0.285 | Acc: 90.41% (28931/32000)
Train Batch: 300/352 | Loss: 0.287 | Acc: 90.33% (34686/38400)
Train Batch: 350/352 | Loss: 0.288 | Acc: 90.26% (40437/44800)
Train Batch: 352/352 | Loss: 0.288 | Acc: 90.25% (40614/45000)
Validation | Loss: 0.334 | Acc: 88.68% (4434/5000)
New best model with accuracy: 0.8868

Epoch 59/200
Train Batch: 50/352 | Loss: 0.253 | Acc: 91.41% (5850/6400)
Train Batch: 100/352 | Loss: 0.264 | Acc: 91.09% (11660/12800)
Train Batch: 150/352 | Loss: 0.274 | Acc: 90.78% (17430/19200)
Train Batch: 200/352 | Loss: 0.275 | Acc: 90.76% (23234/25600)
Train Batch: 250/352 | Loss: 0.275 | Acc: 90.67% (29014/32000)
Train Batch: 300/352 | Loss: 0.279 | Acc: 90.50% (34753/38400)
Train Batch: 350/352 | Loss: 0.279 | Acc: 90.54% (40561/44800)
Train Batch: 352/352 | Loss: 0.280 | Acc: 90.52% (40732/45000)
Validation | Loss: 0.518 | Acc: 83.06% (4153/5000)

Epoch 60/200
Train Batch: 50/352 | Loss: 0.251 | Acc: 91.25% (5840/6400)
Train Batch: 100/352 | Loss: 0.264 | Acc: 90.93% (11639/12800)
Train Batch: 150/352 | Loss: 0.272 | Acc: 90.61% (17398/19200)
Train Batch: 200/352 | Loss: 0.270 | Acc: 90.65% (23206/25600)
Train Batch: 250/352 | Loss: 0.278 | Acc: 90.39% (28926/32000)
Train Batch: 300/352 | Loss: 0.279 | Acc: 90.35% (34694/38400)
Train Batch: 350/352 | Loss: 0.284 | Acc: 90.24% (40427/44800)
Train Batch: 352/352 | Loss: 0.284 | Acc: 90.25% (40611/45000)
Validation | Loss: 0.405 | Acc: 86.52% (4326/5000)

Epoch 61/200
Train Batch: 50/352 | Loss: 0.263 | Acc: 90.89% (5817/6400)
Train Batch: 100/352 | Loss: 0.272 | Acc: 90.72% (11612/12800)
Train Batch: 150/352 | Loss: 0.272 | Acc: 90.83% (17440/19200)
Train Batch: 200/352 | Loss: 0.279 | Acc: 90.57% (23186/25600)
Train Batch: 250/352 | Loss: 0.283 | Acc: 90.41% (28930/32000)
Train Batch: 300/352 | Loss: 0.282 | Acc: 90.47% (34739/38400)
Train Batch: 350/352 | Loss: 0.282 | Acc: 90.42% (40509/44800)
Train Batch: 352/352 | Loss: 0.283 | Acc: 90.41% (40686/45000)
Validation | Loss: 0.471 | Acc: 84.80% (4240/5000)

Epoch 62/200
Train Batch: 50/352 | Loss: 0.269 | Acc: 90.89% (5817/6400)
Train Batch: 100/352 | Loss: 0.270 | Acc: 90.70% (11609/12800)
Train Batch: 150/352 | Loss: 0.277 | Acc: 90.54% (17384/19200)
Train Batch: 200/352 | Loss: 0.278 | Acc: 90.47% (23160/25600)
Train Batch: 250/352 | Loss: 0.283 | Acc: 90.31% (28899/32000)
Train Batch: 300/352 | Loss: 0.284 | Acc: 90.22% (34646/38400)
Train Batch: 350/352 | Loss: 0.284 | Acc: 90.23% (40421/44800)
Train Batch: 352/352 | Loss: 0.284 | Acc: 90.22% (40601/45000)
Validation | Loss: 0.385 | Acc: 86.76% (4338/5000)

Epoch 63/200
Train Batch: 50/352 | Loss: 0.250 | Acc: 91.50% (5856/6400)
Train Batch: 100/352 | Loss: 0.268 | Acc: 90.77% (11618/12800)
Train Batch: 150/352 | Loss: 0.273 | Acc: 90.73% (17420/19200)
Train Batch: 200/352 | Loss: 0.277 | Acc: 90.63% (23201/25600)
Train Batch: 250/352 | Loss: 0.279 | Acc: 90.50% (28959/32000)
Train Batch: 300/352 | Loss: 0.277 | Acc: 90.49% (34747/38400)
Train Batch: 350/352 | Loss: 0.278 | Acc: 90.46% (40525/44800)
Train Batch: 352/352 | Loss: 0.278 | Acc: 90.45% (40703/45000)
Validation | Loss: 0.594 | Acc: 81.46% (4073/5000)

Epoch 64/200
Train Batch: 50/352 | Loss: 0.270 | Acc: 90.81% (5812/6400)
Train Batch: 100/352 | Loss: 0.266 | Acc: 90.96% (11643/12800)
Train Batch: 150/352 | Loss: 0.267 | Acc: 90.91% (17454/19200)
Train Batch: 200/352 | Loss: 0.272 | Acc: 90.71% (23221/25600)
Train Batch: 250/352 | Loss: 0.275 | Acc: 90.60% (28992/32000)
Train Batch: 300/352 | Loss: 0.280 | Acc: 90.46% (34738/38400)
Train Batch: 350/352 | Loss: 0.275 | Acc: 90.65% (40610/44800)
Train Batch: 352/352 | Loss: 0.275 | Acc: 90.64% (40790/45000)
Validation | Loss: 0.351 | Acc: 87.88% (4394/5000)

Epoch 65/200
Train Batch: 50/352 | Loss: 0.264 | Acc: 91.00% (5824/6400)
Train Batch: 100/352 | Loss: 0.267 | Acc: 90.86% (11630/12800)
Train Batch: 150/352 | Loss: 0.264 | Acc: 90.88% (17449/19200)
Train Batch: 200/352 | Loss: 0.268 | Acc: 90.78% (23239/25600)
Train Batch: 250/352 | Loss: 0.272 | Acc: 90.73% (29034/32000)
Train Batch: 300/352 | Loss: 0.273 | Acc: 90.69% (34824/38400)
Train Batch: 350/352 | Loss: 0.276 | Acc: 90.61% (40595/44800)
Train Batch: 352/352 | Loss: 0.276 | Acc: 90.61% (40775/45000)
Validation | Loss: 0.441 | Acc: 85.72% (4286/5000)

Epoch 66/200
Train Batch: 50/352 | Loss: 0.284 | Acc: 90.33% (5781/6400)
Train Batch: 100/352 | Loss: 0.267 | Acc: 90.99% (11647/12800)
Train Batch: 150/352 | Loss: 0.262 | Acc: 91.18% (17507/19200)
Train Batch: 200/352 | Loss: 0.268 | Acc: 90.93% (23277/25600)
Train Batch: 250/352 | Loss: 0.270 | Acc: 90.84% (29070/32000)
Train Batch: 300/352 | Loss: 0.273 | Acc: 90.68% (34822/38400)
Train Batch: 350/352 | Loss: 0.274 | Acc: 90.62% (40596/44800)
Train Batch: 352/352 | Loss: 0.274 | Acc: 90.61% (40775/45000)
Validation | Loss: 0.378 | Acc: 87.52% (4376/5000)

Epoch 67/200
Train Batch: 50/352 | Loss: 0.245 | Acc: 91.94% (5884/6400)
Train Batch: 100/352 | Loss: 0.242 | Acc: 91.86% (11758/12800)
Train Batch: 150/352 | Loss: 0.249 | Acc: 91.54% (17575/19200)
Train Batch: 200/352 | Loss: 0.251 | Acc: 91.47% (23416/25600)
Train Batch: 250/352 | Loss: 0.258 | Acc: 91.23% (29194/32000)
Train Batch: 300/352 | Loss: 0.262 | Acc: 91.08% (34976/38400)
Train Batch: 350/352 | Loss: 0.264 | Acc: 90.96% (40751/44800)
Train Batch: 352/352 | Loss: 0.264 | Acc: 90.94% (40924/45000)
Validation | Loss: 0.668 | Acc: 80.24% (4012/5000)

Epoch 68/200
Train Batch: 50/352 | Loss: 0.262 | Acc: 91.09% (5830/6400)
Train Batch: 100/352 | Loss: 0.264 | Acc: 91.05% (11654/12800)
Train Batch: 150/352 | Loss: 0.267 | Acc: 90.88% (17448/19200)
Train Batch: 200/352 | Loss: 0.271 | Acc: 90.66% (23210/25600)
Train Batch: 250/352 | Loss: 0.272 | Acc: 90.58% (28986/32000)
Train Batch: 300/352 | Loss: 0.269 | Acc: 90.68% (34823/38400)
Train Batch: 350/352 | Loss: 0.274 | Acc: 90.59% (40583/44800)
Train Batch: 352/352 | Loss: 0.274 | Acc: 90.59% (40766/45000)
Validation | Loss: 0.421 | Acc: 86.08% (4304/5000)

Epoch 69/200
Train Batch: 50/352 | Loss: 0.236 | Acc: 92.11% (5895/6400)
Train Batch: 100/352 | Loss: 0.242 | Acc: 91.77% (11746/12800)
Train Batch: 150/352 | Loss: 0.247 | Acc: 91.57% (17581/19200)
Train Batch: 200/352 | Loss: 0.256 | Acc: 91.22% (23352/25600)
Train Batch: 250/352 | Loss: 0.256 | Acc: 91.31% (29220/32000)
Train Batch: 300/352 | Loss: 0.257 | Acc: 91.26% (35042/38400)
Train Batch: 350/352 | Loss: 0.257 | Acc: 91.24% (40877/44800)
Train Batch: 352/352 | Loss: 0.257 | Acc: 91.24% (41060/45000)
Validation | Loss: 0.544 | Acc: 83.00% (4150/5000)

Epoch 70/200
Train Batch: 50/352 | Loss: 0.273 | Acc: 90.56% (5796/6400)
Train Batch: 100/352 | Loss: 0.261 | Acc: 91.06% (11656/12800)
Train Batch: 150/352 | Loss: 0.253 | Acc: 91.28% (17526/19200)
Train Batch: 200/352 | Loss: 0.258 | Acc: 91.12% (23327/25600)
Train Batch: 250/352 | Loss: 0.262 | Acc: 90.97% (29110/32000)
Train Batch: 300/352 | Loss: 0.265 | Acc: 90.91% (34911/38400)
Train Batch: 350/352 | Loss: 0.264 | Acc: 91.00% (40768/44800)
Train Batch: 352/352 | Loss: 0.264 | Acc: 90.98% (40943/45000)
Validation | Loss: 0.392 | Acc: 86.56% (4328/5000)

Epoch 71/200
Train Batch: 50/352 | Loss: 0.259 | Acc: 91.17% (5835/6400)
Train Batch: 100/352 | Loss: 0.249 | Acc: 91.49% (11711/12800)
Train Batch: 150/352 | Loss: 0.254 | Acc: 91.33% (17536/19200)
Train Batch: 200/352 | Loss: 0.254 | Acc: 91.26% (23363/25600)
Train Batch: 250/352 | Loss: 0.257 | Acc: 91.16% (29171/32000)
Train Batch: 300/352 | Loss: 0.258 | Acc: 91.07% (34972/38400)
Train Batch: 350/352 | Loss: 0.260 | Acc: 91.00% (40770/44800)
Train Batch: 352/352 | Loss: 0.260 | Acc: 90.98% (40943/45000)
Validation | Loss: 0.434 | Acc: 85.58% (4279/5000)

Epoch 72/200
Train Batch: 50/352 | Loss: 0.222 | Acc: 92.58% (5925/6400)
Train Batch: 100/352 | Loss: 0.243 | Acc: 91.88% (11760/12800)
Train Batch: 150/352 | Loss: 0.251 | Acc: 91.48% (17564/19200)
Train Batch: 200/352 | Loss: 0.253 | Acc: 91.32% (23378/25600)
Train Batch: 250/352 | Loss: 0.257 | Acc: 91.20% (29184/32000)
Train Batch: 300/352 | Loss: 0.258 | Acc: 91.21% (35024/38400)
Train Batch: 350/352 | Loss: 0.260 | Acc: 91.20% (40857/44800)
Train Batch: 352/352 | Loss: 0.260 | Acc: 91.20% (41040/45000)
Validation | Loss: 0.391 | Acc: 86.42% (4321/5000)

Epoch 73/200
Train Batch: 50/352 | Loss: 0.242 | Acc: 91.52% (5857/6400)
Train Batch: 100/352 | Loss: 0.244 | Acc: 91.34% (11691/12800)
Train Batch: 150/352 | Loss: 0.251 | Acc: 91.17% (17504/19200)
Train Batch: 200/352 | Loss: 0.251 | Acc: 91.15% (23335/25600)
Train Batch: 250/352 | Loss: 0.249 | Acc: 91.28% (29210/32000)
Train Batch: 300/352 | Loss: 0.250 | Acc: 91.27% (35048/38400)
Train Batch: 350/352 | Loss: 0.251 | Acc: 91.25% (40878/44800)
Train Batch: 352/352 | Loss: 0.251 | Acc: 91.25% (41063/45000)
Validation | Loss: 0.344 | Acc: 88.44% (4422/5000)

Epoch 74/200
Train Batch: 50/352 | Loss: 0.250 | Acc: 91.55% (5859/6400)
Train Batch: 100/352 | Loss: 0.241 | Acc: 91.88% (11761/12800)
Train Batch: 150/352 | Loss: 0.241 | Acc: 91.85% (17635/19200)
Train Batch: 200/352 | Loss: 0.251 | Acc: 91.45% (23412/25600)
Train Batch: 250/352 | Loss: 0.252 | Acc: 91.38% (29243/32000)
Train Batch: 300/352 | Loss: 0.255 | Acc: 91.26% (35043/38400)
Train Batch: 350/352 | Loss: 0.256 | Acc: 91.25% (40878/44800)
Train Batch: 352/352 | Loss: 0.257 | Acc: 91.23% (41055/45000)
Validation | Loss: 0.500 | Acc: 83.90% (4195/5000)

Epoch 75/200
Train Batch: 50/352 | Loss: 0.256 | Acc: 90.78% (5810/6400)
Train Batch: 100/352 | Loss: 0.244 | Acc: 91.64% (11730/12800)
Train Batch: 150/352 | Loss: 0.239 | Acc: 91.81% (17627/19200)
Train Batch: 200/352 | Loss: 0.244 | Acc: 91.55% (23438/25600)
Train Batch: 250/352 | Loss: 0.248 | Acc: 91.45% (29264/32000)
Train Batch: 300/352 | Loss: 0.253 | Acc: 91.23% (35033/38400)
Train Batch: 350/352 | Loss: 0.254 | Acc: 91.18% (40849/44800)
Train Batch: 352/352 | Loss: 0.254 | Acc: 91.18% (41033/45000)
Validation | Loss: 0.465 | Acc: 84.62% (4231/5000)

Epoch 76/200
Train Batch: 50/352 | Loss: 0.243 | Acc: 91.91% (5882/6400)
Train Batch: 100/352 | Loss: 0.248 | Acc: 91.54% (11717/12800)
Train Batch: 150/352 | Loss: 0.248 | Acc: 91.48% (17565/19200)
Train Batch: 200/352 | Loss: 0.244 | Acc: 91.59% (23448/25600)
Train Batch: 250/352 | Loss: 0.251 | Acc: 91.33% (29227/32000)
Train Batch: 300/352 | Loss: 0.252 | Acc: 91.29% (35056/38400)
Train Batch: 350/352 | Loss: 0.249 | Acc: 91.42% (40954/44800)
Train Batch: 352/352 | Loss: 0.249 | Acc: 91.43% (41143/45000)
Validation | Loss: 0.498 | Acc: 84.40% (4220/5000)

Epoch 77/200
Train Batch: 50/352 | Loss: 0.231 | Acc: 91.83% (5877/6400)
Train Batch: 100/352 | Loss: 0.240 | Acc: 91.70% (11737/12800)
Train Batch: 150/352 | Loss: 0.241 | Acc: 91.70% (17606/19200)
Train Batch: 200/352 | Loss: 0.242 | Acc: 91.72% (23481/25600)
Train Batch: 250/352 | Loss: 0.240 | Acc: 91.78% (29368/32000)
Train Batch: 300/352 | Loss: 0.243 | Acc: 91.77% (35238/38400)
Train Batch: 350/352 | Loss: 0.245 | Acc: 91.70% (41082/44800)
Train Batch: 352/352 | Loss: 0.245 | Acc: 91.70% (41266/45000)
Validation | Loss: 0.402 | Acc: 86.42% (4321/5000)

Epoch 78/200
Train Batch: 50/352 | Loss: 0.221 | Acc: 92.69% (5932/6400)
Train Batch: 100/352 | Loss: 0.229 | Acc: 92.17% (11798/12800)
Train Batch: 150/352 | Loss: 0.234 | Acc: 92.04% (17672/19200)
Train Batch: 200/352 | Loss: 0.234 | Acc: 92.02% (23557/25600)
Train Batch: 250/352 | Loss: 0.236 | Acc: 91.95% (29425/32000)
Train Batch: 300/352 | Loss: 0.241 | Acc: 91.82% (35259/38400)
Train Batch: 350/352 | Loss: 0.244 | Acc: 91.74% (41099/44800)
Train Batch: 352/352 | Loss: 0.244 | Acc: 91.72% (41276/45000)
Validation | Loss: 0.430 | Acc: 85.96% (4298/5000)

Epoch 79/200
Train Batch: 50/352 | Loss: 0.211 | Acc: 93.11% (5959/6400)
Train Batch: 100/352 | Loss: 0.218 | Acc: 92.88% (11889/12800)
Train Batch: 150/352 | Loss: 0.229 | Acc: 92.36% (17733/19200)
Train Batch: 200/352 | Loss: 0.235 | Acc: 92.12% (23583/25600)
Train Batch: 250/352 | Loss: 0.237 | Acc: 92.07% (29462/32000)
Train Batch: 300/352 | Loss: 0.238 | Acc: 91.97% (35318/38400)
Train Batch: 350/352 | Loss: 0.241 | Acc: 91.89% (41166/44800)
Train Batch: 352/352 | Loss: 0.242 | Acc: 91.88% (41347/45000)
Validation | Loss: 0.520 | Acc: 84.32% (4216/5000)

Epoch 80/200
Train Batch: 50/352 | Loss: 0.225 | Acc: 92.41% (5914/6400)
Train Batch: 100/352 | Loss: 0.233 | Acc: 92.06% (11784/12800)
Train Batch: 150/352 | Loss: 0.230 | Acc: 92.04% (17671/19200)
Train Batch: 200/352 | Loss: 0.238 | Acc: 91.77% (23494/25600)
Train Batch: 250/352 | Loss: 0.239 | Acc: 91.72% (29349/32000)
Train Batch: 300/352 | Loss: 0.240 | Acc: 91.71% (35216/38400)
Train Batch: 350/352 | Loss: 0.241 | Acc: 91.72% (41092/44800)
Train Batch: 352/352 | Loss: 0.242 | Acc: 91.71% (41270/45000)
Validation | Loss: 0.362 | Acc: 88.08% (4404/5000)

Epoch 81/200
Train Batch: 50/352 | Loss: 0.206 | Acc: 93.19% (5964/6400)
Train Batch: 100/352 | Loss: 0.209 | Acc: 92.88% (11888/12800)
Train Batch: 150/352 | Loss: 0.218 | Acc: 92.53% (17766/19200)
Train Batch: 200/352 | Loss: 0.223 | Acc: 92.45% (23666/25600)
Train Batch: 250/352 | Loss: 0.230 | Acc: 92.17% (29493/32000)
Train Batch: 300/352 | Loss: 0.235 | Acc: 92.03% (35339/38400)
Train Batch: 350/352 | Loss: 0.234 | Acc: 92.02% (41223/44800)
Train Batch: 352/352 | Loss: 0.235 | Acc: 92.01% (41406/45000)
Validation | Loss: 0.469 | Acc: 85.84% (4292/5000)

Epoch 82/200
Train Batch: 50/352 | Loss: 0.232 | Acc: 91.91% (5882/6400)
Train Batch: 100/352 | Loss: 0.239 | Acc: 91.53% (11716/12800)
Train Batch: 150/352 | Loss: 0.235 | Acc: 91.69% (17604/19200)
Train Batch: 200/352 | Loss: 0.230 | Acc: 91.93% (23534/25600)
Train Batch: 250/352 | Loss: 0.235 | Acc: 91.82% (29382/32000)
Train Batch: 300/352 | Loss: 0.234 | Acc: 91.89% (35285/38400)
Train Batch: 350/352 | Loss: 0.236 | Acc: 91.79% (41121/44800)
Train Batch: 352/352 | Loss: 0.237 | Acc: 91.79% (41304/45000)
Validation | Loss: 0.354 | Acc: 88.10% (4405/5000)

Epoch 83/200
Train Batch: 50/352 | Loss: 0.194 | Acc: 93.28% (5970/6400)
Train Batch: 100/352 | Loss: 0.214 | Acc: 92.55% (11846/12800)
Train Batch: 150/352 | Loss: 0.216 | Acc: 92.55% (17769/19200)
Train Batch: 200/352 | Loss: 0.223 | Acc: 92.28% (23624/25600)
Train Batch: 250/352 | Loss: 0.228 | Acc: 92.17% (29493/32000)
Train Batch: 300/352 | Loss: 0.229 | Acc: 92.09% (35362/38400)
Train Batch: 350/352 | Loss: 0.233 | Acc: 91.94% (41188/44800)
Train Batch: 352/352 | Loss: 0.234 | Acc: 91.92% (41366/45000)
Validation | Loss: 0.411 | Acc: 87.12% (4356/5000)

Epoch 84/200
Train Batch: 50/352 | Loss: 0.191 | Acc: 93.69% (5996/6400)
Train Batch: 100/352 | Loss: 0.208 | Acc: 92.90% (11891/12800)
Train Batch: 150/352 | Loss: 0.213 | Acc: 92.76% (17809/19200)
Train Batch: 200/352 | Loss: 0.221 | Acc: 92.49% (23677/25600)
Train Batch: 250/352 | Loss: 0.225 | Acc: 92.41% (29571/32000)
Train Batch: 300/352 | Loss: 0.225 | Acc: 92.35% (35462/38400)
Train Batch: 350/352 | Loss: 0.228 | Acc: 92.28% (41342/44800)
Train Batch: 352/352 | Loss: 0.227 | Acc: 92.27% (41523/45000)
Validation | Loss: 0.420 | Acc: 86.76% (4338/5000)

Epoch 85/200
Train Batch: 50/352 | Loss: 0.219 | Acc: 92.34% (5910/6400)
Train Batch: 100/352 | Loss: 0.221 | Acc: 92.37% (11823/12800)
Train Batch: 150/352 | Loss: 0.221 | Acc: 92.39% (17739/19200)
Train Batch: 200/352 | Loss: 0.222 | Acc: 92.30% (23630/25600)
Train Batch: 250/352 | Loss: 0.224 | Acc: 92.28% (29529/32000)
Train Batch: 300/352 | Loss: 0.227 | Acc: 92.18% (35399/38400)
Train Batch: 350/352 | Loss: 0.225 | Acc: 92.22% (41316/44800)
Train Batch: 352/352 | Loss: 0.225 | Acc: 92.22% (41500/45000)
Validation | Loss: 0.316 | Acc: 89.38% (4469/5000)
New best model with accuracy: 0.8938

Epoch 86/200
Train Batch: 50/352 | Loss: 0.211 | Acc: 92.88% (5944/6400)
Train Batch: 100/352 | Loss: 0.218 | Acc: 92.62% (11855/12800)
Train Batch: 150/352 | Loss: 0.214 | Acc: 92.75% (17808/19200)
Train Batch: 200/352 | Loss: 0.221 | Acc: 92.43% (23662/25600)
Train Batch: 250/352 | Loss: 0.223 | Acc: 92.36% (29556/32000)
Train Batch: 300/352 | Loss: 0.225 | Acc: 92.32% (35451/38400)
Train Batch: 350/352 | Loss: 0.222 | Acc: 92.49% (41437/44800)
Train Batch: 352/352 | Loss: 0.222 | Acc: 92.50% (41623/45000)
Validation | Loss: 0.481 | Acc: 84.78% (4239/5000)

Epoch 87/200
Train Batch: 50/352 | Loss: 0.180 | Acc: 93.70% (5997/6400)
Train Batch: 100/352 | Loss: 0.196 | Acc: 93.32% (11945/12800)
Train Batch: 150/352 | Loss: 0.203 | Acc: 93.05% (17865/19200)
Train Batch: 200/352 | Loss: 0.207 | Acc: 92.88% (23776/25600)
Train Batch: 250/352 | Loss: 0.210 | Acc: 92.82% (29703/32000)
Train Batch: 300/352 | Loss: 0.213 | Acc: 92.73% (35610/38400)
Train Batch: 350/352 | Loss: 0.216 | Acc: 92.62% (41496/44800)
Train Batch: 352/352 | Loss: 0.216 | Acc: 92.63% (41683/45000)
Validation | Loss: 0.327 | Acc: 88.48% (4424/5000)

Epoch 88/200
Train Batch: 50/352 | Loss: 0.190 | Acc: 93.61% (5991/6400)
Train Batch: 100/352 | Loss: 0.198 | Acc: 93.30% (11942/12800)
Train Batch: 150/352 | Loss: 0.206 | Acc: 92.92% (17841/19200)
Train Batch: 200/352 | Loss: 0.212 | Acc: 92.62% (23710/25600)
Train Batch: 250/352 | Loss: 0.215 | Acc: 92.60% (29632/32000)
Train Batch: 300/352 | Loss: 0.220 | Acc: 92.42% (35490/38400)
Train Batch: 350/352 | Loss: 0.226 | Acc: 92.30% (41351/44800)
Train Batch: 352/352 | Loss: 0.226 | Acc: 92.32% (41545/45000)
Validation | Loss: 0.329 | Acc: 88.78% (4439/5000)

Epoch 89/200
Train Batch: 50/352 | Loss: 0.183 | Acc: 93.77% (6001/6400)
Train Batch: 100/352 | Loss: 0.187 | Acc: 93.74% (11999/12800)
Train Batch: 150/352 | Loss: 0.196 | Acc: 93.30% (17914/19200)
Train Batch: 200/352 | Loss: 0.206 | Acc: 93.10% (23834/25600)
Train Batch: 250/352 | Loss: 0.210 | Acc: 92.88% (29721/32000)
Train Batch: 300/352 | Loss: 0.211 | Acc: 92.89% (35668/38400)
Train Batch: 350/352 | Loss: 0.214 | Acc: 92.77% (41561/44800)
Train Batch: 352/352 | Loss: 0.214 | Acc: 92.77% (41746/45000)
Validation | Loss: 0.415 | Acc: 87.40% (4370/5000)

Epoch 90/200
Train Batch: 50/352 | Loss: 0.194 | Acc: 93.58% (5989/6400)
Train Batch: 100/352 | Loss: 0.198 | Acc: 93.30% (11943/12800)
Train Batch: 150/352 | Loss: 0.202 | Acc: 93.07% (17870/19200)
Train Batch: 200/352 | Loss: 0.210 | Acc: 92.84% (23767/25600)
Train Batch: 250/352 | Loss: 0.211 | Acc: 92.78% (29688/32000)
Train Batch: 300/352 | Loss: 0.213 | Acc: 92.70% (35597/38400)
Train Batch: 350/352 | Loss: 0.217 | Acc: 92.60% (41484/44800)
Train Batch: 352/352 | Loss: 0.217 | Acc: 92.60% (41672/45000)
Validation | Loss: 0.385 | Acc: 86.90% (4345/5000)

Epoch 91/200
Train Batch: 50/352 | Loss: 0.199 | Acc: 93.05% (5955/6400)
Train Batch: 100/352 | Loss: 0.205 | Acc: 93.07% (11913/12800)
Train Batch: 150/352 | Loss: 0.199 | Acc: 93.32% (17918/19200)
Train Batch: 200/352 | Loss: 0.204 | Acc: 93.12% (23839/25600)
Train Batch: 250/352 | Loss: 0.210 | Acc: 92.84% (29708/32000)
Train Batch: 300/352 | Loss: 0.212 | Acc: 92.73% (35610/38400)
Train Batch: 350/352 | Loss: 0.215 | Acc: 92.65% (41508/44800)
Train Batch: 352/352 | Loss: 0.215 | Acc: 92.66% (41695/45000)
Validation | Loss: 0.406 | Acc: 87.38% (4369/5000)

Epoch 92/200
Train Batch: 50/352 | Loss: 0.211 | Acc: 92.94% (5948/6400)
Train Batch: 100/352 | Loss: 0.201 | Acc: 93.05% (11910/12800)
Train Batch: 150/352 | Loss: 0.203 | Acc: 92.89% (17835/19200)
Train Batch: 200/352 | Loss: 0.205 | Acc: 92.89% (23780/25600)
Train Batch: 250/352 | Loss: 0.206 | Acc: 92.83% (29705/32000)
Train Batch: 300/352 | Loss: 0.214 | Acc: 92.59% (35553/38400)
Train Batch: 350/352 | Loss: 0.215 | Acc: 92.53% (41455/44800)
Train Batch: 352/352 | Loss: 0.215 | Acc: 92.53% (41637/45000)
Validation | Loss: 0.411 | Acc: 86.92% (4346/5000)

Epoch 93/200
Train Batch: 50/352 | Loss: 0.196 | Acc: 93.28% (5970/6400)
Train Batch: 100/352 | Loss: 0.201 | Acc: 93.13% (11921/12800)
Train Batch: 150/352 | Loss: 0.202 | Acc: 93.10% (17875/19200)
Train Batch: 200/352 | Loss: 0.209 | Acc: 92.85% (23769/25600)
Train Batch: 250/352 | Loss: 0.209 | Acc: 92.84% (29709/32000)
Train Batch: 300/352 | Loss: 0.211 | Acc: 92.83% (35646/38400)
Train Batch: 350/352 | Loss: 0.212 | Acc: 92.77% (41561/44800)
Train Batch: 352/352 | Loss: 0.212 | Acc: 92.76% (41743/45000)
Validation | Loss: 0.365 | Acc: 87.50% (4375/5000)

Epoch 94/200
Train Batch: 50/352 | Loss: 0.210 | Acc: 92.73% (5935/6400)
Train Batch: 100/352 | Loss: 0.210 | Acc: 92.96% (11899/12800)
Train Batch: 150/352 | Loss: 0.206 | Acc: 93.04% (17864/19200)
Train Batch: 200/352 | Loss: 0.206 | Acc: 92.99% (23805/25600)
Train Batch: 250/352 | Loss: 0.208 | Acc: 92.89% (29724/32000)
Train Batch: 300/352 | Loss: 0.206 | Acc: 92.95% (35693/38400)
Train Batch: 350/352 | Loss: 0.206 | Acc: 92.98% (41657/44800)
Train Batch: 352/352 | Loss: 0.206 | Acc: 92.99% (41845/45000)
Validation | Loss: 0.395 | Acc: 87.98% (4399/5000)

Epoch 95/200
Train Batch: 50/352 | Loss: 0.208 | Acc: 92.84% (5942/6400)
Train Batch: 100/352 | Loss: 0.206 | Acc: 92.79% (11877/12800)
Train Batch: 150/352 | Loss: 0.206 | Acc: 92.78% (17814/19200)
Train Batch: 200/352 | Loss: 0.210 | Acc: 92.77% (23750/25600)
Train Batch: 250/352 | Loss: 0.211 | Acc: 92.72% (29672/32000)
Train Batch: 300/352 | Loss: 0.210 | Acc: 92.74% (35611/38400)
Train Batch: 350/352 | Loss: 0.210 | Acc: 92.73% (41544/44800)
Train Batch: 352/352 | Loss: 0.210 | Acc: 92.74% (41731/45000)
Validation | Loss: 0.315 | Acc: 89.30% (4465/5000)

Epoch 96/200
Train Batch: 50/352 | Loss: 0.170 | Acc: 94.28% (6034/6400)
Train Batch: 100/352 | Loss: 0.174 | Acc: 94.23% (12062/12800)
Train Batch: 150/352 | Loss: 0.182 | Acc: 93.99% (18047/19200)
Train Batch: 200/352 | Loss: 0.184 | Acc: 93.84% (24022/25600)
Train Batch: 250/352 | Loss: 0.186 | Acc: 93.81% (30019/32000)
Train Batch: 300/352 | Loss: 0.188 | Acc: 93.69% (35976/38400)
Train Batch: 350/352 | Loss: 0.194 | Acc: 93.47% (41875/44800)
Train Batch: 352/352 | Loss: 0.194 | Acc: 93.47% (42060/45000)
Validation | Loss: 0.380 | Acc: 87.66% (4383/5000)

Epoch 97/200
Train Batch: 50/352 | Loss: 0.197 | Acc: 93.70% (5997/6400)
Train Batch: 100/352 | Loss: 0.191 | Acc: 93.71% (11995/12800)
Train Batch: 150/352 | Loss: 0.187 | Acc: 93.77% (18003/19200)
Train Batch: 200/352 | Loss: 0.188 | Acc: 93.71% (23991/25600)
Train Batch: 250/352 | Loss: 0.191 | Acc: 93.57% (29942/32000)
Train Batch: 300/352 | Loss: 0.195 | Acc: 93.39% (35861/38400)
Train Batch: 350/352 | Loss: 0.198 | Acc: 93.29% (41792/44800)
Train Batch: 352/352 | Loss: 0.197 | Acc: 93.29% (41979/45000)
Validation | Loss: 0.431 | Acc: 86.80% (4340/5000)

Epoch 98/200
Train Batch: 50/352 | Loss: 0.178 | Acc: 94.22% (6030/6400)
Train Batch: 100/352 | Loss: 0.178 | Acc: 94.11% (12046/12800)
Train Batch: 150/352 | Loss: 0.185 | Acc: 93.70% (17991/19200)
Train Batch: 200/352 | Loss: 0.192 | Acc: 93.42% (23915/25600)
Train Batch: 250/352 | Loss: 0.197 | Acc: 93.23% (29833/32000)
Train Batch: 300/352 | Loss: 0.199 | Acc: 93.22% (35795/38400)
Train Batch: 350/352 | Loss: 0.198 | Acc: 93.22% (41763/44800)
Train Batch: 352/352 | Loss: 0.198 | Acc: 93.22% (41949/45000)
Validation | Loss: 0.309 | Acc: 89.82% (4491/5000)
New best model with accuracy: 0.8982

Epoch 99/200
Train Batch: 50/352 | Loss: 0.177 | Acc: 94.03% (6018/6400)
Train Batch: 100/352 | Loss: 0.167 | Acc: 94.32% (12073/12800)
Train Batch: 150/352 | Loss: 0.180 | Acc: 93.91% (18031/19200)
Train Batch: 200/352 | Loss: 0.184 | Acc: 93.80% (24014/25600)
Train Batch: 250/352 | Loss: 0.191 | Acc: 93.53% (29929/32000)
Train Batch: 300/352 | Loss: 0.193 | Acc: 93.39% (35861/38400)
Train Batch: 350/352 | Loss: 0.194 | Acc: 93.33% (41812/44800)
Train Batch: 352/352 | Loss: 0.194 | Acc: 93.33% (42000/45000)
Validation | Loss: 0.338 | Acc: 88.70% (4435/5000)

Epoch 100/200
Train Batch: 50/352 | Loss: 0.176 | Acc: 94.06% (6020/6400)
Train Batch: 100/352 | Loss: 0.173 | Acc: 94.16% (12052/12800)
Train Batch: 150/352 | Loss: 0.178 | Acc: 94.02% (18052/19200)
Train Batch: 200/352 | Loss: 0.176 | Acc: 94.04% (24075/25600)
Train Batch: 250/352 | Loss: 0.179 | Acc: 93.96% (30067/32000)
Train Batch: 300/352 | Loss: 0.189 | Acc: 93.60% (35941/38400)
Train Batch: 350/352 | Loss: 0.192 | Acc: 93.46% (41870/44800)
Train Batch: 352/352 | Loss: 0.193 | Acc: 93.45% (42052/45000)
Validation | Loss: 0.345 | Acc: 88.48% (4424/5000)

Epoch 101/200
Train Batch: 50/352 | Loss: 0.158 | Acc: 94.67% (6059/6400)
Train Batch: 100/352 | Loss: 0.167 | Acc: 94.38% (12080/12800)
Train Batch: 150/352 | Loss: 0.177 | Acc: 93.94% (18036/19200)
Train Batch: 200/352 | Loss: 0.178 | Acc: 93.95% (24050/25600)
Train Batch: 250/352 | Loss: 0.180 | Acc: 93.91% (30050/32000)
Train Batch: 300/352 | Loss: 0.183 | Acc: 93.82% (36025/38400)
Train Batch: 350/352 | Loss: 0.184 | Acc: 93.70% (41979/44800)
Train Batch: 352/352 | Loss: 0.185 | Acc: 93.70% (42164/45000)
Validation | Loss: 0.400 | Acc: 87.82% (4391/5000)

Epoch 102/200
Train Batch: 50/352 | Loss: 0.160 | Acc: 94.66% (6058/6400)
Train Batch: 100/352 | Loss: 0.170 | Acc: 94.30% (12071/12800)
Train Batch: 150/352 | Loss: 0.178 | Acc: 93.96% (18040/19200)
Train Batch: 200/352 | Loss: 0.184 | Acc: 93.71% (23990/25600)
Train Batch: 250/352 | Loss: 0.188 | Acc: 93.59% (29948/32000)
Train Batch: 300/352 | Loss: 0.186 | Acc: 93.65% (35963/38400)
Train Batch: 350/352 | Loss: 0.185 | Acc: 93.69% (41971/44800)
Train Batch: 352/352 | Loss: 0.185 | Acc: 93.69% (42161/45000)
Validation | Loss: 0.324 | Acc: 89.60% (4480/5000)

Epoch 103/200
Train Batch: 50/352 | Loss: 0.153 | Acc: 94.64% (6057/6400)
Train Batch: 100/352 | Loss: 0.161 | Acc: 94.38% (12080/12800)
Train Batch: 150/352 | Loss: 0.170 | Acc: 94.21% (18088/19200)
Train Batch: 200/352 | Loss: 0.173 | Acc: 94.07% (24082/25600)
Train Batch: 250/352 | Loss: 0.178 | Acc: 93.90% (30049/32000)
Train Batch: 300/352 | Loss: 0.178 | Acc: 93.91% (36060/38400)
Train Batch: 350/352 | Loss: 0.179 | Acc: 93.91% (42072/44800)
Train Batch: 352/352 | Loss: 0.179 | Acc: 93.92% (42262/45000)
Validation | Loss: 0.344 | Acc: 88.52% (4426/5000)

Epoch 104/200
Train Batch: 50/352 | Loss: 0.159 | Acc: 94.67% (6059/6400)
Train Batch: 100/352 | Loss: 0.171 | Acc: 94.36% (12078/12800)
Train Batch: 150/352 | Loss: 0.176 | Acc: 94.09% (18065/19200)
Train Batch: 200/352 | Loss: 0.179 | Acc: 93.90% (24039/25600)
Train Batch: 250/352 | Loss: 0.179 | Acc: 93.83% (30026/32000)
Train Batch: 300/352 | Loss: 0.180 | Acc: 93.83% (36030/38400)
Train Batch: 350/352 | Loss: 0.180 | Acc: 93.84% (42041/44800)
Train Batch: 352/352 | Loss: 0.180 | Acc: 93.84% (42230/45000)
Validation | Loss: 0.332 | Acc: 89.50% (4475/5000)

Epoch 105/200
Train Batch: 50/352 | Loss: 0.172 | Acc: 93.92% (6011/6400)
Train Batch: 100/352 | Loss: 0.171 | Acc: 94.09% (12044/12800)
Train Batch: 150/352 | Loss: 0.169 | Acc: 94.15% (18076/19200)
Train Batch: 200/352 | Loss: 0.172 | Acc: 94.08% (24084/25600)
Train Batch: 250/352 | Loss: 0.174 | Acc: 94.00% (30080/32000)
Train Batch: 300/352 | Loss: 0.178 | Acc: 93.85% (36040/38400)
Train Batch: 350/352 | Loss: 0.181 | Acc: 93.72% (41988/44800)
Train Batch: 352/352 | Loss: 0.181 | Acc: 93.73% (42177/45000)
Validation | Loss: 0.362 | Acc: 88.12% (4406/5000)

Epoch 106/200
Train Batch: 50/352 | Loss: 0.170 | Acc: 94.33% (6037/6400)
Train Batch: 100/352 | Loss: 0.159 | Acc: 94.62% (12112/12800)
Train Batch: 150/352 | Loss: 0.164 | Acc: 94.48% (18140/19200)
Train Batch: 200/352 | Loss: 0.169 | Acc: 94.27% (24132/25600)
Train Batch: 250/352 | Loss: 0.169 | Acc: 94.26% (30163/32000)
Train Batch: 300/352 | Loss: 0.172 | Acc: 94.22% (36182/38400)
Train Batch: 350/352 | Loss: 0.175 | Acc: 94.10% (42159/44800)
Train Batch: 352/352 | Loss: 0.175 | Acc: 94.09% (42342/45000)
Validation | Loss: 0.340 | Acc: 88.78% (4439/5000)

Epoch 107/200
Train Batch: 50/352 | Loss: 0.170 | Acc: 94.36% (6039/6400)
Train Batch: 100/352 | Loss: 0.172 | Acc: 94.26% (12065/12800)
Train Batch: 150/352 | Loss: 0.170 | Acc: 94.20% (18087/19200)
Train Batch: 200/352 | Loss: 0.172 | Acc: 94.16% (24105/25600)
Train Batch: 250/352 | Loss: 0.174 | Acc: 94.14% (30125/32000)
Train Batch: 300/352 | Loss: 0.175 | Acc: 94.07% (36124/38400)
Train Batch: 350/352 | Loss: 0.177 | Acc: 93.99% (42106/44800)
Train Batch: 352/352 | Loss: 0.177 | Acc: 93.98% (42293/45000)
Validation | Loss: 0.319 | Acc: 89.18% (4459/5000)

Epoch 108/200
Train Batch: 50/352 | Loss: 0.146 | Acc: 94.94% (6076/6400)
Train Batch: 100/352 | Loss: 0.153 | Acc: 94.70% (12121/12800)
Train Batch: 150/352 | Loss: 0.162 | Acc: 94.42% (18129/19200)
Train Batch: 200/352 | Loss: 0.162 | Acc: 94.46% (24182/25600)
Train Batch: 250/352 | Loss: 0.165 | Acc: 94.28% (30169/32000)
Train Batch: 300/352 | Loss: 0.167 | Acc: 94.23% (36184/38400)
Train Batch: 350/352 | Loss: 0.170 | Acc: 94.15% (42180/44800)
Train Batch: 352/352 | Loss: 0.170 | Acc: 94.14% (42364/45000)
Validation | Loss: 0.332 | Acc: 89.34% (4467/5000)

Epoch 109/200
Train Batch: 50/352 | Loss: 0.144 | Acc: 95.39% (6105/6400)
Train Batch: 100/352 | Loss: 0.146 | Acc: 95.20% (12186/12800)
Train Batch: 150/352 | Loss: 0.147 | Acc: 95.15% (18268/19200)
Train Batch: 200/352 | Loss: 0.149 | Acc: 95.01% (24323/25600)
Train Batch: 250/352 | Loss: 0.158 | Acc: 94.74% (30316/32000)
Train Batch: 300/352 | Loss: 0.161 | Acc: 94.59% (36321/38400)
Train Batch: 350/352 | Loss: 0.160 | Acc: 94.63% (42395/44800)
Train Batch: 352/352 | Loss: 0.160 | Acc: 94.63% (42585/45000)
Validation | Loss: 0.380 | Acc: 87.68% (4384/5000)

Epoch 110/200
Train Batch: 50/352 | Loss: 0.158 | Acc: 94.64% (6057/6400)
Train Batch: 100/352 | Loss: 0.158 | Acc: 94.52% (12098/12800)
Train Batch: 150/352 | Loss: 0.157 | Acc: 94.57% (18158/19200)
Train Batch: 200/352 | Loss: 0.156 | Acc: 94.67% (24235/25600)
Train Batch: 250/352 | Loss: 0.156 | Acc: 94.68% (30297/32000)
Train Batch: 300/352 | Loss: 0.157 | Acc: 94.64% (36343/38400)
Train Batch: 350/352 | Loss: 0.158 | Acc: 94.61% (42384/44800)
Train Batch: 352/352 | Loss: 0.159 | Acc: 94.60% (42570/45000)
Validation | Loss: 0.340 | Acc: 88.80% (4440/5000)

Epoch 111/200
Train Batch: 50/352 | Loss: 0.145 | Acc: 95.03% (6082/6400)
Train Batch: 100/352 | Loss: 0.151 | Acc: 94.71% (12123/12800)
Train Batch: 150/352 | Loss: 0.150 | Acc: 94.86% (18213/19200)
Train Batch: 200/352 | Loss: 0.153 | Acc: 94.82% (24274/25600)
Train Batch: 250/352 | Loss: 0.155 | Acc: 94.73% (30314/32000)
Train Batch: 300/352 | Loss: 0.157 | Acc: 94.72% (36372/38400)
Train Batch: 350/352 | Loss: 0.159 | Acc: 94.64% (42400/44800)
Train Batch: 352/352 | Loss: 0.159 | Acc: 94.64% (42588/45000)
Validation | Loss: 0.320 | Acc: 89.82% (4491/5000)

Epoch 112/200
Train Batch: 50/352 | Loss: 0.130 | Acc: 95.66% (6122/6400)
Train Batch: 100/352 | Loss: 0.134 | Acc: 95.62% (12240/12800)
Train Batch: 150/352 | Loss: 0.137 | Acc: 95.48% (18333/19200)
Train Batch: 200/352 | Loss: 0.145 | Acc: 95.19% (24369/25600)
Train Batch: 250/352 | Loss: 0.150 | Acc: 95.05% (30417/32000)
Train Batch: 300/352 | Loss: 0.151 | Acc: 94.98% (36471/38400)
Train Batch: 350/352 | Loss: 0.155 | Acc: 94.84% (42488/44800)
Train Batch: 352/352 | Loss: 0.155 | Acc: 94.84% (42679/45000)
Validation | Loss: 0.302 | Acc: 89.78% (4489/5000)

Epoch 113/200
Train Batch: 50/352 | Loss: 0.144 | Acc: 94.98% (6079/6400)
Train Batch: 100/352 | Loss: 0.138 | Acc: 95.27% (12194/12800)
Train Batch: 150/352 | Loss: 0.139 | Acc: 95.22% (18283/19200)
Train Batch: 200/352 | Loss: 0.143 | Acc: 95.11% (24347/25600)
Train Batch: 250/352 | Loss: 0.151 | Acc: 94.86% (30356/32000)
Train Batch: 300/352 | Loss: 0.150 | Acc: 94.92% (36450/38400)
Train Batch: 350/352 | Loss: 0.153 | Acc: 94.79% (42467/44800)
Train Batch: 352/352 | Loss: 0.153 | Acc: 94.79% (42654/45000)
Validation | Loss: 0.414 | Acc: 87.74% (4387/5000)

Epoch 114/200
Train Batch: 50/352 | Loss: 0.136 | Acc: 95.52% (6113/6400)
Train Batch: 100/352 | Loss: 0.133 | Acc: 95.77% (12259/12800)
Train Batch: 150/352 | Loss: 0.133 | Acc: 95.63% (18361/19200)
Train Batch: 200/352 | Loss: 0.137 | Acc: 95.47% (24440/25600)
Train Batch: 250/352 | Loss: 0.139 | Acc: 95.39% (30525/32000)
Train Batch: 300/352 | Loss: 0.141 | Acc: 95.28% (36588/38400)
Train Batch: 350/352 | Loss: 0.144 | Acc: 95.11% (42610/44800)
Train Batch: 352/352 | Loss: 0.144 | Acc: 95.11% (42801/45000)
Validation | Loss: 0.360 | Acc: 89.06% (4453/5000)

Epoch 115/200
Train Batch: 50/352 | Loss: 0.134 | Acc: 95.36% (6103/6400)
Train Batch: 100/352 | Loss: 0.133 | Acc: 95.40% (12211/12800)
Train Batch: 150/352 | Loss: 0.138 | Acc: 95.30% (18298/19200)
Train Batch: 200/352 | Loss: 0.141 | Acc: 95.21% (24375/25600)
Train Batch: 250/352 | Loss: 0.145 | Acc: 95.07% (30423/32000)
Train Batch: 300/352 | Loss: 0.146 | Acc: 95.07% (36505/38400)
Train Batch: 350/352 | Loss: 0.148 | Acc: 95.01% (42564/44800)
Train Batch: 352/352 | Loss: 0.148 | Acc: 95.01% (42754/45000)
Validation | Loss: 0.268 | Acc: 91.48% (4574/5000)
New best model with accuracy: 0.9148

Epoch 116/200
Train Batch: 50/352 | Loss: 0.124 | Acc: 95.75% (6128/6400)
Train Batch: 100/352 | Loss: 0.131 | Acc: 95.53% (12228/12800)
Train Batch: 150/352 | Loss: 0.133 | Acc: 95.40% (18317/19200)
Train Batch: 200/352 | Loss: 0.135 | Acc: 95.35% (24409/25600)
Train Batch: 250/352 | Loss: 0.135 | Acc: 95.36% (30515/32000)
Train Batch: 300/352 | Loss: 0.139 | Acc: 95.20% (36558/38400)
Train Batch: 350/352 | Loss: 0.143 | Acc: 95.09% (42602/44800)
Train Batch: 352/352 | Loss: 0.143 | Acc: 95.09% (42791/45000)
Validation | Loss: 0.353 | Acc: 88.86% (4443/5000)

Epoch 117/200
Train Batch: 50/352 | Loss: 0.124 | Acc: 95.83% (6133/6400)
Train Batch: 100/352 | Loss: 0.130 | Acc: 95.66% (12245/12800)
Train Batch: 150/352 | Loss: 0.130 | Acc: 95.73% (18380/19200)
Train Batch: 200/352 | Loss: 0.135 | Acc: 95.55% (24460/25600)
Train Batch: 250/352 | Loss: 0.138 | Acc: 95.41% (30531/32000)
Train Batch: 300/352 | Loss: 0.139 | Acc: 95.35% (36616/38400)
Train Batch: 350/352 | Loss: 0.140 | Acc: 95.33% (42710/44800)
Train Batch: 352/352 | Loss: 0.140 | Acc: 95.34% (42901/45000)
Validation | Loss: 0.270 | Acc: 91.82% (4591/5000)
New best model with accuracy: 0.9182

Epoch 118/200
Train Batch: 50/352 | Loss: 0.122 | Acc: 95.62% (6120/6400)
Train Batch: 100/352 | Loss: 0.126 | Acc: 95.62% (12239/12800)
Train Batch: 150/352 | Loss: 0.131 | Acc: 95.50% (18336/19200)
Train Batch: 200/352 | Loss: 0.133 | Acc: 95.47% (24440/25600)
Train Batch: 250/352 | Loss: 0.134 | Acc: 95.45% (30545/32000)
Train Batch: 300/352 | Loss: 0.134 | Acc: 95.46% (36655/38400)
Train Batch: 350/352 | Loss: 0.136 | Acc: 95.40% (42741/44800)
Train Batch: 352/352 | Loss: 0.136 | Acc: 95.40% (42928/45000)
Validation | Loss: 0.270 | Acc: 91.30% (4565/5000)

Epoch 119/200
Train Batch: 50/352 | Loss: 0.114 | Acc: 95.92% (6139/6400)
Train Batch: 100/352 | Loss: 0.125 | Acc: 95.61% (12238/12800)
Train Batch: 150/352 | Loss: 0.124 | Acc: 95.72% (18378/19200)
Train Batch: 200/352 | Loss: 0.126 | Acc: 95.70% (24499/25600)
Train Batch: 250/352 | Loss: 0.129 | Acc: 95.55% (30576/32000)
Train Batch: 300/352 | Loss: 0.132 | Acc: 95.47% (36661/38400)
Train Batch: 350/352 | Loss: 0.136 | Acc: 95.32% (42703/44800)
Train Batch: 352/352 | Loss: 0.136 | Acc: 95.32% (42896/45000)
Validation | Loss: 0.350 | Acc: 89.58% (4479/5000)

Epoch 120/200
Train Batch: 50/352 | Loss: 0.121 | Acc: 96.00% (6144/6400)
Train Batch: 100/352 | Loss: 0.124 | Acc: 95.99% (12287/12800)
Train Batch: 150/352 | Loss: 0.129 | Acc: 95.80% (18393/19200)
Train Batch: 200/352 | Loss: 0.133 | Acc: 95.66% (24488/25600)
Train Batch: 250/352 | Loss: 0.132 | Acc: 95.63% (30601/32000)
Train Batch: 300/352 | Loss: 0.133 | Acc: 95.58% (36703/38400)
Train Batch: 350/352 | Loss: 0.138 | Acc: 95.39% (42736/44800)
Train Batch: 352/352 | Loss: 0.138 | Acc: 95.39% (42925/45000)
Validation | Loss: 0.418 | Acc: 87.68% (4384/5000)

Epoch 121/200
Train Batch: 50/352 | Loss: 0.137 | Acc: 95.55% (6115/6400)
Train Batch: 100/352 | Loss: 0.129 | Acc: 95.73% (12253/12800)
Train Batch: 150/352 | Loss: 0.122 | Acc: 95.99% (18430/19200)
Train Batch: 200/352 | Loss: 0.124 | Acc: 95.98% (24571/25600)
Train Batch: 250/352 | Loss: 0.124 | Acc: 95.91% (30691/32000)
Train Batch: 300/352 | Loss: 0.125 | Acc: 95.81% (36791/38400)
Train Batch: 350/352 | Loss: 0.127 | Acc: 95.72% (42884/44800)
Train Batch: 352/352 | Loss: 0.127 | Acc: 95.72% (43076/45000)
Validation | Loss: 0.340 | Acc: 89.60% (4480/5000)

Epoch 122/200
Train Batch: 50/352 | Loss: 0.114 | Acc: 96.09% (6150/6400)
Train Batch: 100/352 | Loss: 0.111 | Acc: 96.19% (12312/12800)
Train Batch: 150/352 | Loss: 0.114 | Acc: 96.02% (18436/19200)
Train Batch: 200/352 | Loss: 0.118 | Acc: 95.97% (24569/25600)
Train Batch: 250/352 | Loss: 0.120 | Acc: 95.94% (30701/32000)
Train Batch: 300/352 | Loss: 0.123 | Acc: 95.84% (36804/38400)
Train Batch: 350/352 | Loss: 0.124 | Acc: 95.83% (42930/44800)
Train Batch: 352/352 | Loss: 0.124 | Acc: 95.82% (43121/45000)
Validation | Loss: 0.288 | Acc: 91.30% (4565/5000)

Epoch 123/200
Train Batch: 50/352 | Loss: 0.109 | Acc: 96.09% (6150/6400)
Train Batch: 100/352 | Loss: 0.110 | Acc: 96.23% (12318/12800)
Train Batch: 150/352 | Loss: 0.109 | Acc: 96.33% (18496/19200)
Train Batch: 200/352 | Loss: 0.113 | Acc: 96.12% (24608/25600)
Train Batch: 250/352 | Loss: 0.119 | Acc: 95.97% (30712/32000)
Train Batch: 300/352 | Loss: 0.123 | Acc: 95.78% (36781/38400)
Train Batch: 350/352 | Loss: 0.124 | Acc: 95.74% (42890/44800)
Train Batch: 352/352 | Loss: 0.124 | Acc: 95.74% (43082/45000)
Validation | Loss: 0.325 | Acc: 89.90% (4495/5000)

Epoch 124/200
Train Batch: 50/352 | Loss: 0.124 | Acc: 95.95% (6141/6400)
Train Batch: 100/352 | Loss: 0.117 | Acc: 96.15% (12307/12800)
Train Batch: 150/352 | Loss: 0.120 | Acc: 96.00% (18432/19200)
Train Batch: 200/352 | Loss: 0.119 | Acc: 96.00% (24576/25600)
Train Batch: 250/352 | Loss: 0.120 | Acc: 95.98% (30713/32000)
Train Batch: 300/352 | Loss: 0.121 | Acc: 95.93% (36839/38400)
Train Batch: 350/352 | Loss: 0.122 | Acc: 95.91% (42967/44800)
Train Batch: 352/352 | Loss: 0.122 | Acc: 95.90% (43157/45000)
Validation | Loss: 0.293 | Acc: 90.64% (4532/5000)

Epoch 125/200
Train Batch: 50/352 | Loss: 0.116 | Acc: 96.05% (6147/6400)
Train Batch: 100/352 | Loss: 0.115 | Acc: 96.05% (12295/12800)
Train Batch: 150/352 | Loss: 0.114 | Acc: 96.11% (18453/19200)
Train Batch: 200/352 | Loss: 0.114 | Acc: 96.07% (24593/25600)
Train Batch: 250/352 | Loss: 0.117 | Acc: 96.00% (30719/32000)
Train Batch: 300/352 | Loss: 0.118 | Acc: 95.95% (36846/38400)
Train Batch: 350/352 | Loss: 0.121 | Acc: 95.83% (42934/44800)
Train Batch: 352/352 | Loss: 0.122 | Acc: 95.82% (43118/45000)
Validation | Loss: 0.260 | Acc: 91.38% (4569/5000)

Epoch 126/200
Train Batch: 50/352 | Loss: 0.103 | Acc: 96.36% (6167/6400)
Train Batch: 100/352 | Loss: 0.102 | Acc: 96.57% (12361/12800)
Train Batch: 150/352 | Loss: 0.105 | Acc: 96.45% (18519/19200)
Train Batch: 200/352 | Loss: 0.103 | Acc: 96.53% (24712/25600)
Train Batch: 250/352 | Loss: 0.106 | Acc: 96.47% (30871/32000)
Train Batch: 300/352 | Loss: 0.107 | Acc: 96.39% (37015/38400)
Train Batch: 350/352 | Loss: 0.110 | Acc: 96.28% (43133/44800)
Train Batch: 352/352 | Loss: 0.111 | Acc: 96.27% (43323/45000)
Validation | Loss: 0.332 | Acc: 89.90% (4495/5000)

Epoch 127/200
Train Batch: 50/352 | Loss: 0.099 | Acc: 96.89% (6201/6400)
Train Batch: 100/352 | Loss: 0.099 | Acc: 96.77% (12387/12800)
Train Batch: 150/352 | Loss: 0.102 | Acc: 96.64% (18554/19200)
Train Batch: 200/352 | Loss: 0.102 | Acc: 96.66% (24745/25600)
Train Batch: 250/352 | Loss: 0.105 | Acc: 96.54% (30893/32000)
Train Batch: 300/352 | Loss: 0.107 | Acc: 96.48% (37048/38400)
Train Batch: 350/352 | Loss: 0.109 | Acc: 96.37% (43174/44800)
Train Batch: 352/352 | Loss: 0.110 | Acc: 96.36% (43361/45000)
Validation | Loss: 0.253 | Acc: 91.50% (4575/5000)

Epoch 128/200
Train Batch: 50/352 | Loss: 0.098 | Acc: 96.62% (6184/6400)
Train Batch: 100/352 | Loss: 0.099 | Acc: 96.62% (12368/12800)
Train Batch: 150/352 | Loss: 0.105 | Acc: 96.38% (18504/19200)
Train Batch: 200/352 | Loss: 0.108 | Acc: 96.31% (24655/25600)
Train Batch: 250/352 | Loss: 0.109 | Acc: 96.25% (30799/32000)
Train Batch: 300/352 | Loss: 0.110 | Acc: 96.25% (36959/38400)
Train Batch: 350/352 | Loss: 0.113 | Acc: 96.15% (43076/44800)
Train Batch: 352/352 | Loss: 0.113 | Acc: 96.16% (43270/45000)
Validation | Loss: 0.301 | Acc: 90.24% (4512/5000)

Epoch 129/200
Train Batch: 50/352 | Loss: 0.110 | Acc: 96.36% (6167/6400)
Train Batch: 100/352 | Loss: 0.107 | Acc: 96.46% (12347/12800)
Train Batch: 150/352 | Loss: 0.102 | Acc: 96.57% (18541/19200)
Train Batch: 200/352 | Loss: 0.104 | Acc: 96.44% (24689/25600)
Train Batch: 250/352 | Loss: 0.107 | Acc: 96.33% (30825/32000)
Train Batch: 300/352 | Loss: 0.108 | Acc: 96.29% (36976/38400)
Train Batch: 350/352 | Loss: 0.109 | Acc: 96.25% (43118/44800)
Train Batch: 352/352 | Loss: 0.109 | Acc: 96.25% (43311/45000)
Validation | Loss: 0.268 | Acc: 91.46% (4573/5000)

Epoch 130/200
Train Batch: 50/352 | Loss: 0.093 | Acc: 96.97% (6206/6400)
Train Batch: 100/352 | Loss: 0.093 | Acc: 97.04% (12421/12800)
Train Batch: 150/352 | Loss: 0.091 | Acc: 97.06% (18636/19200)
Train Batch: 200/352 | Loss: 0.093 | Acc: 96.98% (24826/25600)
Train Batch: 250/352 | Loss: 0.094 | Acc: 96.94% (31021/32000)
Train Batch: 300/352 | Loss: 0.098 | Acc: 96.77% (37160/38400)
Train Batch: 350/352 | Loss: 0.101 | Acc: 96.64% (43293/44800)
Train Batch: 352/352 | Loss: 0.101 | Acc: 96.63% (43485/45000)
Validation | Loss: 0.342 | Acc: 89.86% (4493/5000)

Epoch 131/200
Train Batch: 50/352 | Loss: 0.096 | Acc: 96.62% (6184/6400)
Train Batch: 100/352 | Loss: 0.091 | Acc: 96.91% (12405/12800)
Train Batch: 150/352 | Loss: 0.094 | Acc: 96.77% (18580/19200)
Train Batch: 200/352 | Loss: 0.093 | Acc: 96.82% (24787/25600)
Train Batch: 250/352 | Loss: 0.094 | Acc: 96.81% (30978/32000)
Train Batch: 300/352 | Loss: 0.094 | Acc: 96.81% (37174/38400)
Train Batch: 350/352 | Loss: 0.096 | Acc: 96.73% (43336/44800)
Train Batch: 352/352 | Loss: 0.096 | Acc: 96.73% (43530/45000)
Validation | Loss: 0.337 | Acc: 89.92% (4496/5000)

Epoch 132/200
Train Batch: 50/352 | Loss: 0.101 | Acc: 96.69% (6188/6400)
Train Batch: 100/352 | Loss: 0.101 | Acc: 96.74% (12383/12800)
Train Batch: 150/352 | Loss: 0.097 | Acc: 96.84% (18593/19200)
Train Batch: 200/352 | Loss: 0.097 | Acc: 96.76% (24771/25600)
Train Batch: 250/352 | Loss: 0.095 | Acc: 96.83% (30984/32000)
Train Batch: 300/352 | Loss: 0.096 | Acc: 96.79% (37169/38400)
Train Batch: 350/352 | Loss: 0.100 | Acc: 96.63% (43291/44800)
Train Batch: 352/352 | Loss: 0.100 | Acc: 96.62% (43481/45000)
Validation | Loss: 0.270 | Acc: 91.76% (4588/5000)

Epoch 133/200
Train Batch: 50/352 | Loss: 0.094 | Acc: 96.89% (6201/6400)
Train Batch: 100/352 | Loss: 0.090 | Acc: 96.90% (12403/12800)
Train Batch: 150/352 | Loss: 0.088 | Acc: 96.94% (18613/19200)
Train Batch: 200/352 | Loss: 0.089 | Acc: 96.94% (24816/25600)
Train Batch: 250/352 | Loss: 0.090 | Acc: 96.90% (31008/32000)
Train Batch: 300/352 | Loss: 0.090 | Acc: 96.90% (37208/38400)
Train Batch: 350/352 | Loss: 0.092 | Acc: 96.84% (43383/44800)
Train Batch: 352/352 | Loss: 0.092 | Acc: 96.84% (43576/45000)
Validation | Loss: 0.213 | Acc: 92.90% (4645/5000)
New best model with accuracy: 0.9290

Epoch 134/200
Train Batch: 50/352 | Loss: 0.090 | Acc: 96.95% (6205/6400)
Train Batch: 100/352 | Loss: 0.088 | Acc: 97.09% (12428/12800)
Train Batch: 150/352 | Loss: 0.088 | Acc: 97.06% (18636/19200)
Train Batch: 200/352 | Loss: 0.089 | Acc: 97.03% (24840/25600)
Train Batch: 250/352 | Loss: 0.090 | Acc: 96.95% (31024/32000)
Train Batch: 300/352 | Loss: 0.088 | Acc: 97.01% (37250/38400)
Train Batch: 350/352 | Loss: 0.089 | Acc: 97.00% (43457/44800)
Train Batch: 352/352 | Loss: 0.089 | Acc: 97.00% (43650/45000)
Validation | Loss: 0.255 | Acc: 92.18% (4609/5000)

Epoch 135/200
Train Batch: 50/352 | Loss: 0.077 | Acc: 97.55% (6243/6400)
Train Batch: 100/352 | Loss: 0.077 | Acc: 97.52% (12482/12800)
Train Batch: 150/352 | Loss: 0.080 | Acc: 97.38% (18696/19200)
Train Batch: 200/352 | Loss: 0.082 | Acc: 97.27% (24901/25600)
Train Batch: 250/352 | Loss: 0.083 | Acc: 97.25% (31119/32000)
Train Batch: 300/352 | Loss: 0.086 | Acc: 97.16% (37311/38400)
Train Batch: 350/352 | Loss: 0.087 | Acc: 97.11% (43506/44800)
Train Batch: 352/352 | Loss: 0.087 | Acc: 97.11% (43700/45000)
Validation | Loss: 0.306 | Acc: 90.96% (4548/5000)

Epoch 136/200
Train Batch: 50/352 | Loss: 0.073 | Acc: 97.61% (6247/6400)
Train Batch: 100/352 | Loss: 0.067 | Acc: 97.77% (12514/12800)
Train Batch: 150/352 | Loss: 0.071 | Acc: 97.66% (18751/19200)
Train Batch: 200/352 | Loss: 0.073 | Acc: 97.60% (24986/25600)
Train Batch: 250/352 | Loss: 0.076 | Acc: 97.50% (31201/32000)
Train Batch: 300/352 | Loss: 0.080 | Acc: 97.32% (37371/38400)
Train Batch: 350/352 | Loss: 0.082 | Acc: 97.22% (43553/44800)
Train Batch: 352/352 | Loss: 0.082 | Acc: 97.22% (43749/45000)
Validation | Loss: 0.268 | Acc: 91.76% (4588/5000)

Epoch 137/200
Train Batch: 50/352 | Loss: 0.079 | Acc: 97.25% (6224/6400)
Train Batch: 100/352 | Loss: 0.076 | Acc: 97.45% (12473/12800)
Train Batch: 150/352 | Loss: 0.074 | Acc: 97.55% (18729/19200)
Train Batch: 200/352 | Loss: 0.075 | Acc: 97.53% (24968/25600)
Train Batch: 250/352 | Loss: 0.075 | Acc: 97.48% (31193/32000)
Train Batch: 300/352 | Loss: 0.076 | Acc: 97.48% (37433/38400)
Train Batch: 350/352 | Loss: 0.078 | Acc: 97.38% (43625/44800)
Train Batch: 352/352 | Loss: 0.078 | Acc: 97.38% (43821/45000)
Validation | Loss: 0.328 | Acc: 90.66% (4533/5000)

Epoch 138/200
Train Batch: 50/352 | Loss: 0.078 | Acc: 97.36% (6231/6400)
Train Batch: 100/352 | Loss: 0.085 | Acc: 97.22% (12444/12800)
Train Batch: 150/352 | Loss: 0.085 | Acc: 97.19% (18660/19200)
Train Batch: 200/352 | Loss: 0.085 | Acc: 97.17% (24876/25600)
Train Batch: 250/352 | Loss: 0.086 | Acc: 97.11% (31076/32000)
Train Batch: 300/352 | Loss: 0.086 | Acc: 97.09% (37284/38400)
Train Batch: 350/352 | Loss: 0.086 | Acc: 97.13% (43514/44800)
Train Batch: 352/352 | Loss: 0.086 | Acc: 97.12% (43706/45000)
Validation | Loss: 0.302 | Acc: 90.92% (4546/5000)

Epoch 139/200
Train Batch: 50/352 | Loss: 0.084 | Acc: 97.20% (6221/6400)
Train Batch: 100/352 | Loss: 0.079 | Acc: 97.35% (12461/12800)
Train Batch: 150/352 | Loss: 0.076 | Acc: 97.47% (18715/19200)
Train Batch: 200/352 | Loss: 0.075 | Acc: 97.54% (24969/25600)
Train Batch: 250/352 | Loss: 0.074 | Acc: 97.57% (31223/32000)
Train Batch: 300/352 | Loss: 0.077 | Acc: 97.48% (37431/38400)
Train Batch: 350/352 | Loss: 0.075 | Acc: 97.53% (43694/44800)
Train Batch: 352/352 | Loss: 0.075 | Acc: 97.54% (43891/45000)
Validation | Loss: 0.274 | Acc: 92.00% (4600/5000)

Epoch 140/200
Train Batch: 50/352 | Loss: 0.072 | Acc: 97.55% (6243/6400)
Train Batch: 100/352 | Loss: 0.077 | Acc: 97.38% (12465/12800)
Train Batch: 150/352 | Loss: 0.077 | Acc: 97.31% (18683/19200)
Train Batch: 200/352 | Loss: 0.075 | Acc: 97.39% (24933/25600)
Train Batch: 250/352 | Loss: 0.073 | Acc: 97.48% (31194/32000)
Train Batch: 300/352 | Loss: 0.073 | Acc: 97.49% (37437/38400)
Train Batch: 350/352 | Loss: 0.075 | Acc: 97.42% (43642/44800)
Train Batch: 352/352 | Loss: 0.075 | Acc: 97.41% (43834/45000)
Validation | Loss: 0.252 | Acc: 92.34% (4617/5000)

Epoch 141/200
Train Batch: 50/352 | Loss: 0.065 | Acc: 97.83% (6261/6400)
Train Batch: 100/352 | Loss: 0.061 | Acc: 98.02% (12546/12800)
Train Batch: 150/352 | Loss: 0.063 | Acc: 97.91% (18799/19200)
Train Batch: 200/352 | Loss: 0.066 | Acc: 97.77% (25029/25600)
Train Batch: 250/352 | Loss: 0.067 | Acc: 97.78% (31288/32000)
Train Batch: 300/352 | Loss: 0.069 | Acc: 97.69% (37514/38400)
Train Batch: 350/352 | Loss: 0.070 | Acc: 97.66% (43750/44800)
Train Batch: 352/352 | Loss: 0.070 | Acc: 97.66% (43947/45000)
Validation | Loss: 0.303 | Acc: 90.98% (4549/5000)

Epoch 142/200
Train Batch: 50/352 | Loss: 0.070 | Acc: 97.77% (6257/6400)
Train Batch: 100/352 | Loss: 0.066 | Acc: 97.85% (12525/12800)
Train Batch: 150/352 | Loss: 0.066 | Acc: 97.81% (18779/19200)
Train Batch: 200/352 | Loss: 0.066 | Acc: 97.83% (25044/25600)
Train Batch: 250/352 | Loss: 0.066 | Acc: 97.85% (31312/32000)
Train Batch: 300/352 | Loss: 0.066 | Acc: 97.82% (37563/38400)
Train Batch: 350/352 | Loss: 0.067 | Acc: 97.80% (43816/44800)
Train Batch: 352/352 | Loss: 0.067 | Acc: 97.80% (44012/45000)
Validation | Loss: 0.277 | Acc: 92.26% (4613/5000)

Epoch 143/200
Train Batch: 50/352 | Loss: 0.056 | Acc: 98.11% (6279/6400)
Train Batch: 100/352 | Loss: 0.060 | Acc: 98.03% (12548/12800)
Train Batch: 150/352 | Loss: 0.062 | Acc: 97.98% (18813/19200)
Train Batch: 200/352 | Loss: 0.063 | Acc: 97.91% (25066/25600)
Train Batch: 250/352 | Loss: 0.066 | Acc: 97.80% (31296/32000)
Train Batch: 300/352 | Loss: 0.067 | Acc: 97.71% (37522/38400)
Train Batch: 350/352 | Loss: 0.069 | Acc: 97.63% (43738/44800)
Train Batch: 352/352 | Loss: 0.069 | Acc: 97.63% (43933/45000)
Validation | Loss: 0.292 | Acc: 91.22% (4561/5000)

Epoch 144/200
Train Batch: 50/352 | Loss: 0.063 | Acc: 97.91% (6266/6400)
Train Batch: 100/352 | Loss: 0.061 | Acc: 98.04% (12549/12800)
Train Batch: 150/352 | Loss: 0.059 | Acc: 98.09% (18833/19200)
Train Batch: 200/352 | Loss: 0.059 | Acc: 98.07% (25107/25600)
Train Batch: 250/352 | Loss: 0.061 | Acc: 98.00% (31361/32000)
Train Batch: 300/352 | Loss: 0.061 | Acc: 97.97% (37621/38400)
Train Batch: 350/352 | Loss: 0.062 | Acc: 97.95% (43883/44800)
Train Batch: 352/352 | Loss: 0.062 | Acc: 97.95% (44079/45000)
Validation | Loss: 0.252 | Acc: 92.60% (4630/5000)

Epoch 145/200
Train Batch: 50/352 | Loss: 0.042 | Acc: 98.72% (6318/6400)
Train Batch: 100/352 | Loss: 0.044 | Acc: 98.67% (12630/12800)
Train Batch: 150/352 | Loss: 0.047 | Acc: 98.55% (18921/19200)
Train Batch: 200/352 | Loss: 0.050 | Acc: 98.41% (25192/25600)
Train Batch: 250/352 | Loss: 0.051 | Acc: 98.38% (31480/32000)
Train Batch: 300/352 | Loss: 0.052 | Acc: 98.35% (37767/38400)
Train Batch: 350/352 | Loss: 0.054 | Acc: 98.27% (44025/44800)
Train Batch: 352/352 | Loss: 0.054 | Acc: 98.27% (44223/45000)
Validation | Loss: 0.301 | Acc: 91.82% (4591/5000)

Epoch 146/200
Train Batch: 50/352 | Loss: 0.058 | Acc: 97.98% (6271/6400)
Train Batch: 100/352 | Loss: 0.053 | Acc: 98.19% (12568/12800)
Train Batch: 150/352 | Loss: 0.052 | Acc: 98.25% (18864/19200)
Train Batch: 200/352 | Loss: 0.052 | Acc: 98.25% (25152/25600)
Train Batch: 250/352 | Loss: 0.052 | Acc: 98.27% (31445/32000)
Train Batch: 300/352 | Loss: 0.055 | Acc: 98.19% (37704/38400)
Train Batch: 350/352 | Loss: 0.055 | Acc: 98.23% (44006/44800)
Train Batch: 352/352 | Loss: 0.055 | Acc: 98.22% (44200/45000)
Validation | Loss: 0.268 | Acc: 92.90% (4645/5000)

Epoch 147/200
Train Batch: 50/352 | Loss: 0.055 | Acc: 98.16% (6282/6400)
Train Batch: 100/352 | Loss: 0.051 | Acc: 98.29% (12581/12800)
Train Batch: 150/352 | Loss: 0.049 | Acc: 98.38% (18888/19200)
Train Batch: 200/352 | Loss: 0.051 | Acc: 98.35% (25178/25600)
Train Batch: 250/352 | Loss: 0.051 | Acc: 98.37% (31477/32000)
Train Batch: 300/352 | Loss: 0.052 | Acc: 98.32% (37755/38400)
Train Batch: 350/352 | Loss: 0.052 | Acc: 98.34% (44058/44800)
Train Batch: 352/352 | Loss: 0.052 | Acc: 98.33% (44250/45000)
Validation | Loss: 0.235 | Acc: 93.18% (4659/5000)
New best model with accuracy: 0.9318

Epoch 148/200
Train Batch: 50/352 | Loss: 0.048 | Acc: 98.47% (6302/6400)
Train Batch: 100/352 | Loss: 0.048 | Acc: 98.43% (12599/12800)
Train Batch: 150/352 | Loss: 0.047 | Acc: 98.49% (18910/19200)
Train Batch: 200/352 | Loss: 0.047 | Acc: 98.48% (25212/25600)
Train Batch: 250/352 | Loss: 0.047 | Acc: 98.47% (31509/32000)
Train Batch: 300/352 | Loss: 0.049 | Acc: 98.41% (37790/38400)
Train Batch: 350/352 | Loss: 0.050 | Acc: 98.36% (44064/44800)
Train Batch: 352/352 | Loss: 0.050 | Acc: 98.36% (44261/45000)
Validation | Loss: 0.298 | Acc: 91.60% (4580/5000)

Epoch 149/200
Train Batch: 50/352 | Loss: 0.040 | Acc: 98.75% (6320/6400)
Train Batch: 100/352 | Loss: 0.040 | Acc: 98.75% (12640/12800)
Train Batch: 150/352 | Loss: 0.041 | Acc: 98.69% (18949/19200)
Train Batch: 200/352 | Loss: 0.041 | Acc: 98.66% (25258/25600)
Train Batch: 250/352 | Loss: 0.042 | Acc: 98.64% (31565/32000)
Train Batch: 300/352 | Loss: 0.044 | Acc: 98.57% (37850/38400)
Train Batch: 350/352 | Loss: 0.045 | Acc: 98.50% (44126/44800)
Train Batch: 352/352 | Loss: 0.045 | Acc: 98.49% (44322/45000)
Validation | Loss: 0.249 | Acc: 93.02% (4651/5000)

Epoch 150/200
Train Batch: 50/352 | Loss: 0.039 | Acc: 98.80% (6323/6400)
Train Batch: 100/352 | Loss: 0.038 | Acc: 98.87% (12655/12800)
Train Batch: 150/352 | Loss: 0.039 | Acc: 98.80% (18970/19200)
Train Batch: 200/352 | Loss: 0.040 | Acc: 98.72% (25272/25600)
Train Batch: 250/352 | Loss: 0.043 | Acc: 98.67% (31576/32000)
Train Batch: 300/352 | Loss: 0.043 | Acc: 98.65% (37883/38400)
Train Batch: 350/352 | Loss: 0.045 | Acc: 98.59% (44167/44800)
Train Batch: 352/352 | Loss: 0.045 | Acc: 98.58% (44363/45000)
Validation | Loss: 0.288 | Acc: 92.36% (4618/5000)

Epoch 151/200
Train Batch: 50/352 | Loss: 0.035 | Acc: 98.88% (6328/6400)
Train Batch: 100/352 | Loss: 0.038 | Acc: 98.81% (12648/12800)
Train Batch: 150/352 | Loss: 0.039 | Acc: 98.74% (18958/19200)
Train Batch: 200/352 | Loss: 0.040 | Acc: 98.75% (25279/25600)
Train Batch: 250/352 | Loss: 0.041 | Acc: 98.74% (31598/32000)
Train Batch: 300/352 | Loss: 0.041 | Acc: 98.68% (37895/38400)
Train Batch: 350/352 | Loss: 0.041 | Acc: 98.66% (44198/44800)
Train Batch: 352/352 | Loss: 0.041 | Acc: 98.65% (44393/45000)
Validation | Loss: 0.215 | Acc: 93.64% (4682/5000)
New best model with accuracy: 0.9364

Epoch 152/200
Train Batch: 50/352 | Loss: 0.037 | Acc: 98.92% (6331/6400)
Train Batch: 100/352 | Loss: 0.039 | Acc: 98.88% (12657/12800)
Train Batch: 150/352 | Loss: 0.036 | Acc: 98.96% (19001/19200)
Train Batch: 200/352 | Loss: 0.034 | Acc: 99.00% (25345/25600)
Train Batch: 250/352 | Loss: 0.034 | Acc: 98.98% (31674/32000)
Train Batch: 300/352 | Loss: 0.034 | Acc: 98.95% (37995/38400)
Train Batch: 350/352 | Loss: 0.035 | Acc: 98.92% (44316/44800)
Train Batch: 352/352 | Loss: 0.035 | Acc: 98.92% (44514/45000)
Validation | Loss: 0.256 | Acc: 93.02% (4651/5000)

Epoch 153/200
Train Batch: 50/352 | Loss: 0.035 | Acc: 99.00% (6336/6400)
Train Batch: 100/352 | Loss: 0.033 | Acc: 99.04% (12677/12800)
Train Batch: 150/352 | Loss: 0.032 | Acc: 99.11% (19030/19200)
Train Batch: 200/352 | Loss: 0.034 | Acc: 99.00% (25345/25600)
Train Batch: 250/352 | Loss: 0.035 | Acc: 98.93% (31657/32000)
Train Batch: 300/352 | Loss: 0.036 | Acc: 98.90% (37979/38400)
Train Batch: 350/352 | Loss: 0.035 | Acc: 98.94% (44327/44800)
Train Batch: 352/352 | Loss: 0.035 | Acc: 98.94% (44524/45000)
Validation | Loss: 0.251 | Acc: 93.44% (4672/5000)

Epoch 154/200
Train Batch: 50/352 | Loss: 0.027 | Acc: 99.20% (6349/6400)
Train Batch: 100/352 | Loss: 0.027 | Acc: 99.13% (12689/12800)
Train Batch: 150/352 | Loss: 0.027 | Acc: 99.17% (19040/19200)
Train Batch: 200/352 | Loss: 0.027 | Acc: 99.11% (25373/25600)
Train Batch: 250/352 | Loss: 0.028 | Acc: 99.08% (31704/32000)
Train Batch: 300/352 | Loss: 0.030 | Acc: 99.06% (38038/38400)
Train Batch: 350/352 | Loss: 0.030 | Acc: 99.05% (44376/44800)
Train Batch: 352/352 | Loss: 0.030 | Acc: 99.06% (44575/45000)
Validation | Loss: 0.270 | Acc: 92.96% (4648/5000)

Epoch 155/200
Train Batch: 50/352 | Loss: 0.029 | Acc: 98.95% (6333/6400)
Train Batch: 100/352 | Loss: 0.028 | Acc: 99.09% (12683/12800)
Train Batch: 150/352 | Loss: 0.028 | Acc: 99.08% (19023/19200)
Train Batch: 200/352 | Loss: 0.029 | Acc: 99.05% (25357/25600)
Train Batch: 250/352 | Loss: 0.029 | Acc: 99.07% (31701/32000)
Train Batch: 300/352 | Loss: 0.030 | Acc: 99.04% (38032/38400)
Train Batch: 350/352 | Loss: 0.031 | Acc: 99.03% (44365/44800)
Train Batch: 352/352 | Loss: 0.031 | Acc: 99.03% (44564/45000)
Validation | Loss: 0.248 | Acc: 93.12% (4656/5000)

Epoch 156/200
Train Batch: 50/352 | Loss: 0.029 | Acc: 99.00% (6336/6400)
Train Batch: 100/352 | Loss: 0.029 | Acc: 99.04% (12677/12800)
Train Batch: 150/352 | Loss: 0.028 | Acc: 99.06% (19019/19200)
Train Batch: 200/352 | Loss: 0.029 | Acc: 99.07% (25361/25600)
Train Batch: 250/352 | Loss: 0.029 | Acc: 99.09% (31710/32000)
Train Batch: 300/352 | Loss: 0.029 | Acc: 99.09% (38051/38400)
Train Batch: 350/352 | Loss: 0.029 | Acc: 99.09% (44393/44800)
Train Batch: 352/352 | Loss: 0.029 | Acc: 99.09% (44590/45000)
Validation | Loss: 0.239 | Acc: 93.74% (4687/5000)
New best model with accuracy: 0.9374

Epoch 157/200
Train Batch: 50/352 | Loss: 0.028 | Acc: 99.19% (6348/6400)
Train Batch: 100/352 | Loss: 0.025 | Acc: 99.27% (12707/12800)
Train Batch: 150/352 | Loss: 0.027 | Acc: 99.23% (19053/19200)
Train Batch: 200/352 | Loss: 0.026 | Acc: 99.25% (25409/25600)
Train Batch: 250/352 | Loss: 0.025 | Acc: 99.28% (31768/32000)
Train Batch: 300/352 | Loss: 0.024 | Acc: 99.29% (38129/38400)
Train Batch: 350/352 | Loss: 0.025 | Acc: 99.26% (44468/44800)
Train Batch: 352/352 | Loss: 0.025 | Acc: 99.26% (44665/45000)
Validation | Loss: 0.249 | Acc: 93.48% (4674/5000)

Epoch 158/200
Train Batch: 50/352 | Loss: 0.027 | Acc: 99.12% (6344/6400)
Train Batch: 100/352 | Loss: 0.026 | Acc: 99.19% (12696/12800)
Train Batch: 150/352 | Loss: 0.025 | Acc: 99.19% (19045/19200)
Train Batch: 200/352 | Loss: 0.025 | Acc: 99.21% (25398/25600)
Train Batch: 250/352 | Loss: 0.025 | Acc: 99.21% (31746/32000)
Train Batch: 300/352 | Loss: 0.025 | Acc: 99.20% (38091/38400)
Train Batch: 350/352 | Loss: 0.026 | Acc: 99.17% (44429/44800)
Train Batch: 352/352 | Loss: 0.026 | Acc: 99.17% (44625/45000)
Validation | Loss: 0.232 | Acc: 94.38% (4719/5000)
New best model with accuracy: 0.9438

Epoch 159/200
Train Batch: 50/352 | Loss: 0.023 | Acc: 99.33% (6357/6400)
Train Batch: 100/352 | Loss: 0.021 | Acc: 99.38% (12721/12800)
Train Batch: 150/352 | Loss: 0.021 | Acc: 99.36% (19077/19200)
Train Batch: 200/352 | Loss: 0.023 | Acc: 99.34% (25430/25600)
Train Batch: 250/352 | Loss: 0.024 | Acc: 99.30% (31777/32000)
Train Batch: 300/352 | Loss: 0.024 | Acc: 99.30% (38133/38400)
Train Batch: 350/352 | Loss: 0.024 | Acc: 99.30% (44485/44800)
Train Batch: 352/352 | Loss: 0.024 | Acc: 99.29% (44681/45000)
Validation | Loss: 0.254 | Acc: 93.26% (4663/5000)

Epoch 160/200
Train Batch: 50/352 | Loss: 0.026 | Acc: 99.34% (6358/6400)
Train Batch: 100/352 | Loss: 0.023 | Acc: 99.38% (12721/12800)
Train Batch: 150/352 | Loss: 0.023 | Acc: 99.41% (19087/19200)
Train Batch: 200/352 | Loss: 0.021 | Acc: 99.44% (25457/25600)
Train Batch: 250/352 | Loss: 0.021 | Acc: 99.45% (31823/32000)
Train Batch: 300/352 | Loss: 0.021 | Acc: 99.46% (38193/38400)
Train Batch: 350/352 | Loss: 0.021 | Acc: 99.46% (44556/44800)
Train Batch: 352/352 | Loss: 0.021 | Acc: 99.46% (44755/45000)
Validation | Loss: 0.215 | Acc: 94.24% (4712/5000)

Epoch 161/200
Train Batch: 50/352 | Loss: 0.014 | Acc: 99.62% (6376/6400)
Train Batch: 100/352 | Loss: 0.016 | Acc: 99.57% (12745/12800)
Train Batch: 150/352 | Loss: 0.017 | Acc: 99.53% (19110/19200)
Train Batch: 200/352 | Loss: 0.018 | Acc: 99.50% (25473/25600)
Train Batch: 250/352 | Loss: 0.019 | Acc: 99.47% (31829/32000)
Train Batch: 300/352 | Loss: 0.019 | Acc: 99.50% (38208/38400)
Train Batch: 350/352 | Loss: 0.019 | Acc: 99.49% (44572/44800)
Train Batch: 352/352 | Loss: 0.019 | Acc: 99.49% (44770/45000)
Validation | Loss: 0.219 | Acc: 94.32% (4716/5000)

Epoch 162/200
Train Batch: 50/352 | Loss: 0.014 | Acc: 99.61% (6375/6400)
Train Batch: 100/352 | Loss: 0.014 | Acc: 99.59% (12747/12800)
Train Batch: 150/352 | Loss: 0.014 | Acc: 99.60% (19123/19200)
Train Batch: 200/352 | Loss: 0.014 | Acc: 99.62% (25503/25600)
Train Batch: 250/352 | Loss: 0.014 | Acc: 99.62% (31879/32000)
Train Batch: 300/352 | Loss: 0.014 | Acc: 99.63% (38257/38400)
Train Batch: 350/352 | Loss: 0.014 | Acc: 99.62% (44629/44800)
Train Batch: 352/352 | Loss: 0.014 | Acc: 99.62% (44827/45000)
Validation | Loss: 0.246 | Acc: 93.92% (4696/5000)

Epoch 163/200
Train Batch: 50/352 | Loss: 0.016 | Acc: 99.45% (6365/6400)
Train Batch: 100/352 | Loss: 0.015 | Acc: 99.48% (12733/12800)
Train Batch: 150/352 | Loss: 0.015 | Acc: 99.48% (19101/19200)
Train Batch: 200/352 | Loss: 0.015 | Acc: 99.53% (25480/25600)
Train Batch: 250/352 | Loss: 0.015 | Acc: 99.51% (31844/32000)
Train Batch: 300/352 | Loss: 0.016 | Acc: 99.51% (38210/38400)
Train Batch: 350/352 | Loss: 0.016 | Acc: 99.52% (44584/44800)
Train Batch: 352/352 | Loss: 0.016 | Acc: 99.52% (44783/45000)
Validation | Loss: 0.215 | Acc: 94.30% (4715/5000)

Epoch 164/200
Train Batch: 50/352 | Loss: 0.012 | Acc: 99.73% (6383/6400)
Train Batch: 100/352 | Loss: 0.011 | Acc: 99.77% (12771/12800)
Train Batch: 150/352 | Loss: 0.010 | Acc: 99.77% (19156/19200)
Train Batch: 200/352 | Loss: 0.011 | Acc: 99.74% (25533/25600)
Train Batch: 250/352 | Loss: 0.011 | Acc: 99.74% (31916/32000)
Train Batch: 300/352 | Loss: 0.011 | Acc: 99.74% (38299/38400)
Train Batch: 350/352 | Loss: 0.011 | Acc: 99.73% (44680/44800)
Train Batch: 352/352 | Loss: 0.011 | Acc: 99.73% (44878/45000)
Validation | Loss: 0.219 | Acc: 94.32% (4716/5000)

Epoch 165/200
Train Batch: 50/352 | Loss: 0.011 | Acc: 99.67% (6379/6400)
Train Batch: 100/352 | Loss: 0.009 | Acc: 99.77% (12771/12800)
Train Batch: 150/352 | Loss: 0.010 | Acc: 99.76% (19153/19200)
Train Batch: 200/352 | Loss: 0.010 | Acc: 99.75% (25536/25600)
Train Batch: 250/352 | Loss: 0.009 | Acc: 99.77% (31926/32000)
Train Batch: 300/352 | Loss: 0.009 | Acc: 99.76% (38309/38400)
Train Batch: 350/352 | Loss: 0.009 | Acc: 99.76% (44691/44800)
Train Batch: 352/352 | Loss: 0.009 | Acc: 99.76% (44891/45000)
Validation | Loss: 0.222 | Acc: 94.22% (4711/5000)

Epoch 166/200
Train Batch: 50/352 | Loss: 0.009 | Acc: 99.80% (6387/6400)
Train Batch: 100/352 | Loss: 0.012 | Acc: 99.68% (12759/12800)
Train Batch: 150/352 | Loss: 0.011 | Acc: 99.69% (19141/19200)
Train Batch: 200/352 | Loss: 0.012 | Acc: 99.68% (25517/25600)
Train Batch: 250/352 | Loss: 0.011 | Acc: 99.71% (31906/32000)
Train Batch: 300/352 | Loss: 0.011 | Acc: 99.71% (38290/38400)
Train Batch: 350/352 | Loss: 0.011 | Acc: 99.71% (44670/44800)
Train Batch: 352/352 | Loss: 0.011 | Acc: 99.71% (44870/45000)
Validation | Loss: 0.216 | Acc: 94.54% (4727/5000)
New best model with accuracy: 0.9454

Epoch 167/200
Train Batch: 50/352 | Loss: 0.008 | Acc: 99.88% (6392/6400)
Train Batch: 100/352 | Loss: 0.008 | Acc: 99.84% (12780/12800)
Train Batch: 150/352 | Loss: 0.008 | Acc: 99.86% (19174/19200)
Train Batch: 200/352 | Loss: 0.008 | Acc: 99.85% (25561/25600)
Train Batch: 250/352 | Loss: 0.008 | Acc: 99.83% (31945/32000)
Train Batch: 300/352 | Loss: 0.008 | Acc: 99.82% (38329/38400)
Train Batch: 350/352 | Loss: 0.008 | Acc: 99.82% (44718/44800)
Train Batch: 352/352 | Loss: 0.008 | Acc: 99.82% (44917/45000)
Validation | Loss: 0.215 | Acc: 94.48% (4724/5000)

Epoch 168/200
Train Batch: 50/352 | Loss: 0.007 | Acc: 99.86% (6391/6400)
Train Batch: 100/352 | Loss: 0.007 | Acc: 99.88% (12784/12800)
Train Batch: 150/352 | Loss: 0.006 | Acc: 99.90% (19181/19200)
Train Batch: 200/352 | Loss: 0.006 | Acc: 99.91% (25576/25600)
Train Batch: 250/352 | Loss: 0.006 | Acc: 99.89% (31966/32000)
Train Batch: 300/352 | Loss: 0.006 | Acc: 99.89% (38358/38400)
Train Batch: 350/352 | Loss: 0.006 | Acc: 99.88% (44748/44800)
Train Batch: 352/352 | Loss: 0.006 | Acc: 99.88% (44948/45000)
Validation | Loss: 0.215 | Acc: 94.78% (4739/5000)
New best model with accuracy: 0.9478

Epoch 169/200
Train Batch: 50/352 | Loss: 0.006 | Acc: 99.89% (6393/6400)
Train Batch: 100/352 | Loss: 0.006 | Acc: 99.90% (12787/12800)
Train Batch: 150/352 | Loss: 0.006 | Acc: 99.89% (19179/19200)
Train Batch: 200/352 | Loss: 0.006 | Acc: 99.90% (25574/25600)
Train Batch: 250/352 | Loss: 0.006 | Acc: 99.89% (31965/32000)
Train Batch: 300/352 | Loss: 0.006 | Acc: 99.90% (38361/38400)
Train Batch: 350/352 | Loss: 0.006 | Acc: 99.90% (44755/44800)
Train Batch: 352/352 | Loss: 0.006 | Acc: 99.90% (44955/45000)
Validation | Loss: 0.191 | Acc: 95.12% (4756/5000)
New best model with accuracy: 0.9512

Epoch 170/200
Train Batch: 50/352 | Loss: 0.005 | Acc: 99.92% (6395/6400)
Train Batch: 100/352 | Loss: 0.004 | Acc: 99.95% (12793/12800)
Train Batch: 150/352 | Loss: 0.005 | Acc: 99.93% (19187/19200)
Train Batch: 200/352 | Loss: 0.004 | Acc: 99.93% (25582/25600)
Train Batch: 250/352 | Loss: 0.005 | Acc: 99.92% (31976/32000)
Train Batch: 300/352 | Loss: 0.005 | Acc: 99.92% (38369/38400)
Train Batch: 350/352 | Loss: 0.005 | Acc: 99.92% (44763/44800)
Train Batch: 352/352 | Loss: 0.005 | Acc: 99.92% (44962/45000)
Validation | Loss: 0.205 | Acc: 94.64% (4732/5000)

Epoch 171/200
Train Batch: 50/352 | Loss: 0.005 | Acc: 99.86% (6391/6400)
Train Batch: 100/352 | Loss: 0.005 | Acc: 99.88% (12785/12800)
Train Batch: 150/352 | Loss: 0.005 | Acc: 99.91% (19182/19200)
Train Batch: 200/352 | Loss: 0.005 | Acc: 99.91% (25578/25600)
Train Batch: 250/352 | Loss: 0.004 | Acc: 99.92% (31975/32000)
Train Batch: 300/352 | Loss: 0.004 | Acc: 99.92% (38370/38400)
Train Batch: 350/352 | Loss: 0.004 | Acc: 99.92% (44766/44800)
Train Batch: 352/352 | Loss: 0.004 | Acc: 99.92% (44966/45000)
Validation | Loss: 0.196 | Acc: 95.28% (4764/5000)
New best model with accuracy: 0.9528

Epoch 172/200
Train Batch: 50/352 | Loss: 0.003 | Acc: 100.00% (6400/6400)
Train Batch: 100/352 | Loss: 0.004 | Acc: 99.96% (12795/12800)
Train Batch: 150/352 | Loss: 0.004 | Acc: 99.97% (19194/19200)
Train Batch: 200/352 | Loss: 0.004 | Acc: 99.96% (25591/25600)
Train Batch: 250/352 | Loss: 0.004 | Acc: 99.96% (31988/32000)
Train Batch: 300/352 | Loss: 0.004 | Acc: 99.97% (38387/38400)
Train Batch: 350/352 | Loss: 0.004 | Acc: 99.96% (44783/44800)
Train Batch: 352/352 | Loss: 0.004 | Acc: 99.96% (44983/45000)
Validation | Loss: 0.178 | Acc: 95.62% (4781/5000)
New best model with accuracy: 0.9562

Epoch 173/200
Train Batch: 50/352 | Loss: 0.003 | Acc: 99.92% (6395/6400)
Train Batch: 100/352 | Loss: 0.003 | Acc: 99.94% (12792/12800)
Train Batch: 150/352 | Loss: 0.003 | Acc: 99.95% (19190/19200)
Train Batch: 200/352 | Loss: 0.003 | Acc: 99.95% (25587/25600)
Train Batch: 250/352 | Loss: 0.003 | Acc: 99.96% (31986/32000)
Train Batch: 300/352 | Loss: 0.003 | Acc: 99.95% (38381/38400)
Train Batch: 350/352 | Loss: 0.003 | Acc: 99.95% (44777/44800)
Train Batch: 352/352 | Loss: 0.003 | Acc: 99.95% (44977/45000)
Validation | Loss: 0.180 | Acc: 95.66% (4783/5000)
New best model with accuracy: 0.9566

Epoch 174/200
Train Batch: 50/352 | Loss: 0.003 | Acc: 99.98% (6399/6400)
Train Batch: 100/352 | Loss: 0.003 | Acc: 99.97% (12796/12800)
Train Batch: 150/352 | Loss: 0.003 | Acc: 99.97% (19194/19200)
Train Batch: 200/352 | Loss: 0.003 | Acc: 99.97% (25593/25600)
Train Batch: 250/352 | Loss: 0.003 | Acc: 99.98% (31993/32000)
Train Batch: 300/352 | Loss: 0.003 | Acc: 99.97% (38390/38400)
Train Batch: 350/352 | Loss: 0.003 | Acc: 99.97% (44787/44800)
Train Batch: 352/352 | Loss: 0.003 | Acc: 99.97% (44987/45000)
Validation | Loss: 0.177 | Acc: 95.60% (4780/5000)

Epoch 175/200
Train Batch: 50/352 | Loss: 0.003 | Acc: 99.97% (6398/6400)
Train Batch: 100/352 | Loss: 0.003 | Acc: 99.96% (12795/12800)
Train Batch: 150/352 | Loss: 0.003 | Acc: 99.97% (19195/19200)
Train Batch: 200/352 | Loss: 0.003 | Acc: 99.96% (25591/25600)
Train Batch: 250/352 | Loss: 0.003 | Acc: 99.97% (31989/32000)
Train Batch: 300/352 | Loss: 0.003 | Acc: 99.97% (38389/38400)
Train Batch: 350/352 | Loss: 0.003 | Acc: 99.97% (44788/44800)
Train Batch: 352/352 | Loss: 0.003 | Acc: 99.97% (44988/45000)
Validation | Loss: 0.175 | Acc: 95.62% (4781/5000)

Epoch 176/200
Train Batch: 50/352 | Loss: 0.002 | Acc: 99.98% (6399/6400)
Train Batch: 100/352 | Loss: 0.002 | Acc: 99.98% (12798/12800)
Train Batch: 150/352 | Loss: 0.002 | Acc: 99.99% (19198/19200)
Train Batch: 200/352 | Loss: 0.002 | Acc: 99.99% (25598/25600)
Train Batch: 250/352 | Loss: 0.002 | Acc: 99.99% (31998/32000)
Train Batch: 300/352 | Loss: 0.002 | Acc: 99.98% (38394/38400)
Train Batch: 350/352 | Loss: 0.002 | Acc: 99.99% (44794/44800)
Train Batch: 352/352 | Loss: 0.002 | Acc: 99.99% (44994/45000)
Validation | Loss: 0.189 | Acc: 95.36% (4768/5000)

Epoch 177/200
Train Batch: 50/352 | Loss: 0.003 | Acc: 99.95% (6397/6400)
Train Batch: 100/352 | Loss: 0.003 | Acc: 99.95% (12794/12800)
Train Batch: 150/352 | Loss: 0.003 | Acc: 99.95% (19191/19200)
Train Batch: 200/352 | Loss: 0.003 | Acc: 99.95% (25588/25600)
Train Batch: 250/352 | Loss: 0.003 | Acc: 99.96% (31986/32000)
Train Batch: 300/352 | Loss: 0.003 | Acc: 99.96% (38386/38400)
Train Batch: 350/352 | Loss: 0.003 | Acc: 99.96% (44783/44800)
Train Batch: 352/352 | Loss: 0.003 | Acc: 99.96% (44983/45000)
Validation | Loss: 0.177 | Acc: 95.58% (4779/5000)

Epoch 178/200
Train Batch: 50/352 | Loss: 0.002 | Acc: 100.00% (6400/6400)
Train Batch: 100/352 | Loss: 0.002 | Acc: 100.00% (12800/12800)
Train Batch: 150/352 | Loss: 0.002 | Acc: 99.99% (19198/19200)
Train Batch: 200/352 | Loss: 0.002 | Acc: 99.99% (25598/25600)
Train Batch: 250/352 | Loss: 0.002 | Acc: 99.99% (31996/32000)
Train Batch: 300/352 | Loss: 0.002 | Acc: 99.98% (38392/38400)
Train Batch: 350/352 | Loss: 0.002 | Acc: 99.98% (44792/44800)
Train Batch: 352/352 | Loss: 0.002 | Acc: 99.98% (44992/45000)
Validation | Loss: 0.171 | Acc: 95.68% (4784/5000)
New best model with accuracy: 0.9568

Epoch 179/200
Train Batch: 50/352 | Loss: 0.003 | Acc: 99.98% (6399/6400)
Train Batch: 100/352 | Loss: 0.003 | Acc: 99.98% (12798/12800)
Train Batch: 150/352 | Loss: 0.003 | Acc: 99.99% (19198/19200)
Train Batch: 200/352 | Loss: 0.003 | Acc: 99.99% (25597/25600)
Train Batch: 250/352 | Loss: 0.003 | Acc: 99.98% (31994/32000)
Train Batch: 300/352 | Loss: 0.002 | Acc: 99.98% (38393/38400)
Train Batch: 350/352 | Loss: 0.002 | Acc: 99.98% (44793/44800)
Train Batch: 352/352 | Loss: 0.002 | Acc: 99.98% (44993/45000)
Validation | Loss: 0.173 | Acc: 95.64% (4782/5000)

Epoch 180/200
Train Batch: 50/352 | Loss: 0.002 | Acc: 99.98% (6399/6400)
Train Batch: 100/352 | Loss: 0.002 | Acc: 99.97% (12796/12800)
Train Batch: 150/352 | Loss: 0.002 | Acc: 99.97% (19195/19200)
Train Batch: 200/352 | Loss: 0.002 | Acc: 99.98% (25595/25600)
Train Batch: 250/352 | Loss: 0.002 | Acc: 99.98% (31995/32000)
Train Batch: 300/352 | Loss: 0.002 | Acc: 99.98% (38394/38400)
Train Batch: 350/352 | Loss: 0.002 | Acc: 99.98% (44790/44800)
Train Batch: 352/352 | Loss: 0.002 | Acc: 99.98% (44990/45000)
Validation | Loss: 0.179 | Acc: 95.54% (4777/5000)

Epoch 181/200
Train Batch: 50/352 | Loss: 0.002 | Acc: 100.00% (6400/6400)
Train Batch: 100/352 | Loss: 0.002 | Acc: 99.99% (12799/12800)
Train Batch: 150/352 | Loss: 0.002 | Acc: 99.99% (19198/19200)
Train Batch: 200/352 | Loss: 0.002 | Acc: 99.99% (25597/25600)
Train Batch: 250/352 | Loss: 0.002 | Acc: 99.99% (31997/32000)
Train Batch: 300/352 | Loss: 0.002 | Acc: 99.99% (38396/38400)
Train Batch: 350/352 | Loss: 0.002 | Acc: 99.99% (44795/44800)
Train Batch: 352/352 | Loss: 0.002 | Acc: 99.99% (44995/45000)
Validation | Loss: 0.180 | Acc: 95.46% (4773/5000)

Epoch 182/200
Train Batch: 50/352 | Loss: 0.002 | Acc: 100.00% (6400/6400)
Train Batch: 100/352 | Loss: 0.002 | Acc: 99.99% (12799/12800)
Train Batch: 150/352 | Loss: 0.002 | Acc: 99.99% (19199/19200)
Train Batch: 200/352 | Loss: 0.002 | Acc: 99.99% (25597/25600)
Train Batch: 250/352 | Loss: 0.002 | Acc: 99.99% (31997/32000)
Train Batch: 300/352 | Loss: 0.002 | Acc: 99.99% (38397/38400)
Train Batch: 350/352 | Loss: 0.002 | Acc: 99.99% (44797/44800)
Train Batch: 352/352 | Loss: 0.002 | Acc: 99.99% (44997/45000)
Validation | Loss: 0.174 | Acc: 95.70% (4785/5000)
New best model with accuracy: 0.9570

Epoch 183/200
Train Batch: 50/352 | Loss: 0.002 | Acc: 99.98% (6399/6400)
Train Batch: 100/352 | Loss: 0.002 | Acc: 99.99% (12799/12800)
Train Batch: 150/352 | Loss: 0.002 | Acc: 99.99% (19199/19200)
Train Batch: 200/352 | Loss: 0.002 | Acc: 100.00% (25599/25600)
Train Batch: 250/352 | Loss: 0.002 | Acc: 99.99% (31998/32000)
Train Batch: 300/352 | Loss: 0.002 | Acc: 99.99% (38398/38400)
Train Batch: 350/352 | Loss: 0.002 | Acc: 100.00% (44798/44800)
Train Batch: 352/352 | Loss: 0.002 | Acc: 100.00% (44998/45000)
Validation | Loss: 0.171 | Acc: 95.78% (4789/5000)
New best model with accuracy: 0.9578

Epoch 184/200
Train Batch: 50/352 | Loss: 0.002 | Acc: 100.00% (6400/6400)
Train Batch: 100/352 | Loss: 0.002 | Acc: 100.00% (12800/12800)
Train Batch: 150/352 | Loss: 0.002 | Acc: 100.00% (19200/19200)
Train Batch: 200/352 | Loss: 0.002 | Acc: 100.00% (25599/25600)
Train Batch: 250/352 | Loss: 0.002 | Acc: 99.99% (31998/32000)
Train Batch: 300/352 | Loss: 0.002 | Acc: 99.99% (38398/38400)
Train Batch: 350/352 | Loss: 0.002 | Acc: 100.00% (44798/44800)
Train Batch: 352/352 | Loss: 0.002 | Acc: 100.00% (44998/45000)
Validation | Loss: 0.171 | Acc: 95.66% (4783/5000)

Epoch 185/200
Train Batch: 50/352 | Loss: 0.002 | Acc: 100.00% (6400/6400)
Train Batch: 100/352 | Loss: 0.002 | Acc: 100.00% (12800/12800)
Train Batch: 150/352 | Loss: 0.002 | Acc: 100.00% (19200/19200)
Train Batch: 200/352 | Loss: 0.002 | Acc: 100.00% (25600/25600)
Train Batch: 250/352 | Loss: 0.002 | Acc: 100.00% (32000/32000)
Train Batch: 300/352 | Loss: 0.002 | Acc: 100.00% (38400/38400)
Train Batch: 350/352 | Loss: 0.002 | Acc: 100.00% (44799/44800)
Train Batch: 352/352 | Loss: 0.002 | Acc: 100.00% (44998/45000)
Validation | Loss: 0.171 | Acc: 95.66% (4783/5000)

Epoch 186/200
Train Batch: 50/352 | Loss: 0.002 | Acc: 99.98% (6399/6400)
Train Batch: 100/352 | Loss: 0.002 | Acc: 99.98% (12798/12800)
Train Batch: 150/352 | Loss: 0.002 | Acc: 99.99% (19198/19200)
Train Batch: 200/352 | Loss: 0.002 | Acc: 99.99% (25598/25600)
Train Batch: 250/352 | Loss: 0.002 | Acc: 99.99% (31998/32000)
Train Batch: 300/352 | Loss: 0.002 | Acc: 99.99% (38396/38400)
Train Batch: 350/352 | Loss: 0.002 | Acc: 99.99% (44796/44800)
Train Batch: 352/352 | Loss: 0.002 | Acc: 99.99% (44996/45000)
Validation | Loss: 0.168 | Acc: 95.74% (4787/5000)

Epoch 187/200
Train Batch: 50/352 | Loss: 0.002 | Acc: 100.00% (6400/6400)
Train Batch: 100/352 | Loss: 0.002 | Acc: 100.00% (12800/12800)
Train Batch: 150/352 | Loss: 0.002 | Acc: 100.00% (19200/19200)
Train Batch: 200/352 | Loss: 0.002 | Acc: 100.00% (25600/25600)
Train Batch: 250/352 | Loss: 0.002 | Acc: 100.00% (31999/32000)
Train Batch: 300/352 | Loss: 0.002 | Acc: 99.99% (38398/38400)
Train Batch: 350/352 | Loss: 0.002 | Acc: 100.00% (44798/44800)
Train Batch: 352/352 | Loss: 0.002 | Acc: 100.00% (44998/45000)
Validation | Loss: 0.167 | Acc: 95.78% (4789/5000)

Epoch 188/200
Train Batch: 50/352 | Loss: 0.002 | Acc: 100.00% (6400/6400)
Train Batch: 100/352 | Loss: 0.002 | Acc: 100.00% (12800/12800)
Train Batch: 150/352 | Loss: 0.002 | Acc: 99.99% (19199/19200)
Train Batch: 200/352 | Loss: 0.002 | Acc: 100.00% (25599/25600)
Train Batch: 250/352 | Loss: 0.002 | Acc: 100.00% (31999/32000)
Train Batch: 300/352 | Loss: 0.002 | Acc: 100.00% (38399/38400)
Train Batch: 350/352 | Loss: 0.002 | Acc: 100.00% (44799/44800)
Train Batch: 352/352 | Loss: 0.002 | Acc: 100.00% (44999/45000)
Validation | Loss: 0.169 | Acc: 95.84% (4792/5000)
New best model with accuracy: 0.9584

Epoch 189/200
Train Batch: 50/352 | Loss: 0.002 | Acc: 99.98% (6399/6400)
Train Batch: 100/352 | Loss: 0.002 | Acc: 99.99% (12799/12800)
Train Batch: 150/352 | Loss: 0.002 | Acc: 99.99% (19199/19200)
Train Batch: 200/352 | Loss: 0.002 | Acc: 100.00% (25599/25600)
Train Batch: 250/352 | Loss: 0.002 | Acc: 100.00% (31999/32000)
Train Batch: 300/352 | Loss: 0.002 | Acc: 100.00% (38399/38400)
Train Batch: 350/352 | Loss: 0.002 | Acc: 100.00% (44798/44800)
Train Batch: 352/352 | Loss: 0.002 | Acc: 100.00% (44998/45000)
Validation | Loss: 0.169 | Acc: 95.84% (4792/5000)

Epoch 190/200
Train Batch: 50/352 | Loss: 0.002 | Acc: 100.00% (6400/6400)
Train Batch: 100/352 | Loss: 0.002 | Acc: 99.98% (12798/12800)
Train Batch: 150/352 | Loss: 0.002 | Acc: 99.99% (19198/19200)
Train Batch: 200/352 | Loss: 0.002 | Acc: 99.99% (25598/25600)
Train Batch: 250/352 | Loss: 0.002 | Acc: 99.99% (31996/32000)
Train Batch: 300/352 | Loss: 0.002 | Acc: 99.99% (38395/38400)
Train Batch: 350/352 | Loss: 0.002 | Acc: 99.99% (44795/44800)
Train Batch: 352/352 | Loss: 0.002 | Acc: 99.99% (44995/45000)
Validation | Loss: 0.168 | Acc: 95.86% (4793/5000)
New best model with accuracy: 0.9586

Epoch 191/200
Train Batch: 50/352 | Loss: 0.002 | Acc: 99.98% (6399/6400)
Train Batch: 100/352 | Loss: 0.002 | Acc: 99.99% (12799/12800)
Train Batch: 150/352 | Loss: 0.002 | Acc: 99.99% (19199/19200)
Train Batch: 200/352 | Loss: 0.002 | Acc: 99.99% (25598/25600)
Train Batch: 250/352 | Loss: 0.002 | Acc: 99.99% (31998/32000)
Train Batch: 300/352 | Loss: 0.002 | Acc: 99.99% (38398/38400)
Train Batch: 350/352 | Loss: 0.002 | Acc: 100.00% (44798/44800)
Train Batch: 352/352 | Loss: 0.002 | Acc: 100.00% (44998/45000)
Validation | Loss: 0.170 | Acc: 95.78% (4789/5000)

Epoch 192/200
Train Batch: 50/352 | Loss: 0.002 | Acc: 100.00% (6400/6400)
Train Batch: 100/352 | Loss: 0.002 | Acc: 100.00% (12800/12800)
Train Batch: 150/352 | Loss: 0.002 | Acc: 99.99% (19199/19200)
Train Batch: 200/352 | Loss: 0.002 | Acc: 100.00% (25599/25600)
Train Batch: 250/352 | Loss: 0.002 | Acc: 100.00% (31999/32000)
Train Batch: 300/352 | Loss: 0.002 | Acc: 99.99% (38397/38400)
Train Batch: 350/352 | Loss: 0.002 | Acc: 99.99% (44797/44800)
Train Batch: 352/352 | Loss: 0.002 | Acc: 99.99% (44997/45000)
Validation | Loss: 0.172 | Acc: 95.68% (4784/5000)

Epoch 193/200
Train Batch: 50/352 | Loss: 0.002 | Acc: 99.97% (6398/6400)
Train Batch: 100/352 | Loss: 0.002 | Acc: 99.98% (12798/12800)
Train Batch: 150/352 | Loss: 0.002 | Acc: 99.99% (19198/19200)
Train Batch: 200/352 | Loss: 0.002 | Acc: 99.99% (25598/25600)
Train Batch: 250/352 | Loss: 0.002 | Acc: 99.99% (31997/32000)
Train Batch: 300/352 | Loss: 0.002 | Acc: 99.99% (38397/38400)
Train Batch: 350/352 | Loss: 0.002 | Acc: 99.99% (44797/44800)
Train Batch: 352/352 | Loss: 0.002 | Acc: 99.99% (44997/45000)
Validation | Loss: 0.170 | Acc: 95.74% (4787/5000)

Epoch 194/200
Train Batch: 50/352 | Loss: 0.002 | Acc: 100.00% (6400/6400)
Train Batch: 100/352 | Loss: 0.002 | Acc: 100.00% (12800/12800)
Train Batch: 150/352 | Loss: 0.002 | Acc: 100.00% (19200/19200)
Train Batch: 200/352 | Loss: 0.002 | Acc: 100.00% (25600/25600)
Train Batch: 250/352 | Loss: 0.002 | Acc: 100.00% (32000/32000)
Train Batch: 300/352 | Loss: 0.002 | Acc: 100.00% (38400/38400)
Train Batch: 350/352 | Loss: 0.002 | Acc: 100.00% (44799/44800)
Train Batch: 352/352 | Loss: 0.002 | Acc: 100.00% (44999/45000)
Validation | Loss: 0.167 | Acc: 95.80% (4790/5000)

Epoch 195/200
Train Batch: 50/352 | Loss: 0.002 | Acc: 100.00% (6400/6400)
Train Batch: 100/352 | Loss: 0.002 | Acc: 99.98% (12797/12800)
Train Batch: 150/352 | Loss: 0.002 | Acc: 99.98% (19197/19200)
Train Batch: 200/352 | Loss: 0.002 | Acc: 99.99% (25597/25600)
Train Batch: 250/352 | Loss: 0.002 | Acc: 99.99% (31996/32000)
Train Batch: 300/352 | Loss: 0.002 | Acc: 99.99% (38396/38400)
Train Batch: 350/352 | Loss: 0.002 | Acc: 99.99% (44796/44800)
Train Batch: 352/352 | Loss: 0.002 | Acc: 99.99% (44996/45000)
Validation | Loss: 0.168 | Acc: 95.64% (4782/5000)

Epoch 196/200
Train Batch: 50/352 | Loss: 0.002 | Acc: 100.00% (6400/6400)
Train Batch: 100/352 | Loss: 0.002 | Acc: 99.99% (12799/12800)
Train Batch: 150/352 | Loss: 0.002 | Acc: 99.99% (19198/19200)
Train Batch: 200/352 | Loss: 0.002 | Acc: 99.99% (25597/25600)
Train Batch: 250/352 | Loss: 0.002 | Acc: 99.99% (31997/32000)
Train Batch: 300/352 | Loss: 0.002 | Acc: 99.99% (38397/38400)
Train Batch: 350/352 | Loss: 0.002 | Acc: 99.99% (44796/44800)
Train Batch: 352/352 | Loss: 0.002 | Acc: 99.99% (44995/45000)
Validation | Loss: 0.169 | Acc: 95.68% (4784/5000)

Epoch 197/200
Train Batch: 50/352 | Loss: 0.002 | Acc: 100.00% (6400/6400)
Train Batch: 100/352 | Loss: 0.002 | Acc: 100.00% (12800/12800)
Train Batch: 150/352 | Loss: 0.002 | Acc: 100.00% (19200/19200)
Train Batch: 200/352 | Loss: 0.002 | Acc: 100.00% (25600/25600)
Train Batch: 250/352 | Loss: 0.002 | Acc: 100.00% (32000/32000)
Train Batch: 300/352 | Loss: 0.002 | Acc: 100.00% (38400/38400)
Train Batch: 350/352 | Loss: 0.002 | Acc: 100.00% (44800/44800)
Train Batch: 352/352 | Loss: 0.002 | Acc: 100.00% (45000/45000)
Validation | Loss: 0.168 | Acc: 95.72% (4786/5000)

Epoch 198/200
Train Batch: 50/352 | Loss: 0.002 | Acc: 99.98% (6399/6400)
Train Batch: 100/352 | Loss: 0.002 | Acc: 99.99% (12799/12800)
Train Batch: 150/352 | Loss: 0.002 | Acc: 99.99% (19199/19200)
Train Batch: 200/352 | Loss: 0.002 | Acc: 100.00% (25599/25600)
Train Batch: 250/352 | Loss: 0.002 | Acc: 100.00% (31999/32000)
Train Batch: 300/352 | Loss: 0.002 | Acc: 100.00% (38399/38400)
Train Batch: 350/352 | Loss: 0.002 | Acc: 100.00% (44798/44800)
Train Batch: 352/352 | Loss: 0.002 | Acc: 100.00% (44998/45000)
Validation | Loss: 0.168 | Acc: 95.74% (4787/5000)

Epoch 199/200
Train Batch: 50/352 | Loss: 0.002 | Acc: 99.97% (6398/6400)
Train Batch: 100/352 | Loss: 0.002 | Acc: 99.98% (12798/12800)
Train Batch: 150/352 | Loss: 0.002 | Acc: 99.98% (19197/19200)
Train Batch: 200/352 | Loss: 0.002 | Acc: 99.99% (25597/25600)
Train Batch: 250/352 | Loss: 0.002 | Acc: 99.99% (31996/32000)
Train Batch: 300/352 | Loss: 0.002 | Acc: 99.99% (38395/38400)
Train Batch: 350/352 | Loss: 0.002 | Acc: 99.99% (44795/44800)
Train Batch: 352/352 | Loss: 0.002 | Acc: 99.99% (44995/45000)
Validation | Loss: 0.170 | Acc: 95.66% (4783/5000)

Epoch 200/200
Train Batch: 50/352 | Loss: 0.002 | Acc: 100.00% (6400/6400)
Train Batch: 100/352 | Loss: 0.002 | Acc: 99.98% (12798/12800)
Train Batch: 150/352 | Loss: 0.002 | Acc: 99.99% (19198/19200)
Train Batch: 200/352 | Loss: 0.002 | Acc: 99.99% (25597/25600)
Train Batch: 250/352 | Loss: 0.002 | Acc: 99.99% (31997/32000)
Train Batch: 300/352 | Loss: 0.002 | Acc: 99.99% (38397/38400)
Train Batch: 350/352 | Loss: 0.002 | Acc: 99.99% (44797/44800)
Train Batch: 352/352 | Loss: 0.002 | Acc: 99.99% (44997/45000)
Validation | Loss: 0.168 | Acc: 95.70% (4785/5000)

Training completed in 6931.71 seconds
Best validation accuracy: 0.9586 at epoch 190
Training history saved to /home/tf2387/7123pj_zzp/outputs/training_history.csv
